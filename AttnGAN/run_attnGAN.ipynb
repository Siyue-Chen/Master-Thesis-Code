{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "run_attnGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3rCY0cr2yVC",
        "outputId": "6cffae3f-1f07-4f48-c320-d089b0f078d5"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\")\n",
        "\n",
        "!git clone https://github.com/taoxugit/AttnGAN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 11.51 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AkpyZ8MFFx-x",
        "outputId": "489de5b0-c5b6-4240-af62-7cbcc2b280ab"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b36WSRkdFXH5",
        "outputId": "ff4f3798-5967-44fb-aa77-b3eb3942cebc"
      },
      "source": [
        "!apt-get install python2.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python2.7 is already the newest version (2.7.17-1~18.04ubuntu1.2).\n",
            "python2.7 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPa3FlSyF6Tp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jTiUE9Z2UEx",
        "outputId": "2c5bc29c-5b92-49b2-837b-d5233130c005"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PBu5o9GGPU1"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/AttnGAN/code\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1aH5zg0CJ7n",
        "outputId": "4a16146f-7ef4-402f-d3c5-6424dec99ad0"
      },
      "source": [
        "#ungrade pytorch version\n",
        "!pip install torch==1.1.0 torchvision==0.3.0\n",
        "!pip install pillow==6.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision==0.3.0 in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: pillow==6.1 in /usr/local/lib/python3.7/dist-packages (6.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeE-83lc3HHU",
        "outputId": "d5cb1d61-390d-41e3-eb81-378a0401dfc7"
      },
      "source": [
        "!pip install tensorboard\n",
        "!pip install python-dateutil\n",
        "!pip install easydict\n",
        "!pip install pandas\n",
        "#!pip install pandasy\n",
        "!pip install torchfile\n",
        "!pip install nltk\n",
        "!pip install scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (54.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil) (1.15.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=dfc420caf172d108e7ae206c7ae82df88b9eab82d3cbdeb54f4ca16359b4f77a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built torchfile\n",
            "Installing collected packages: torchfile\n",
            "Successfully installed torchfile-0.1.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (6.1.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLB7js9YP4Ch"
      },
      "source": [
        "#upload ttf file\n",
        "from PIL import ImageFont\n",
        "fnt = ImageFont.truetype('/usr/local/share/fonts/FreeMono.ttf', 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4HOmOWCc2FXI",
        "outputId": "9fc46a92-2bf4-431a-9d12-a696b3282666"
      },
      "source": [
        "%run main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 200,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder200.pth',\n",
            "           'NET_G': '',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100%|██████████| 108857766/108857766 [00:01<00:00, 88453725.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AttnGAN/code/miscc/utils.py:296: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/drive/My Drive/AttnGAN/code/miscc/utils.py:291: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# of netsD 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "errD0: 0.61 errD1: 0.90 errD2: 1.26 \n",
            "g_loss0: 8.56 g_loss1: 15.34 g_loss2: 1.75 w_loss: 27.86 s_loss: 28.48 kl_loss: 0.01 \n",
            "errD0: 0.74 errD1: 0.62 errD2: 1.70 \n",
            "g_loss0: 9.10 g_loss1: 10.93 g_loss2: 0.95 w_loss: 25.80 s_loss: 28.22 kl_loss: 0.01 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/AttnGAN/code/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;34m'''generate images from pre-extracted embeddings'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/AttnGAN/code/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0moptimizersD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0merrD_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merrD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mD_logs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'errD%d: %.2f '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m#######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIPiHpjaFgDZ",
        "outputId": "1b7b728c-20cf-449a-e3fb-c994b0a56c91"
      },
      "source": [
        "%run main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 200,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder200.pth',\n",
            "           'NET_G': '',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 50},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100%|██████████| 108857766/108857766 [00:00<00:00, 134710633.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AttnGAN/code/miscc/utils.py:296: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/drive/My Drive/AttnGAN/code/miscc/utils.py:291: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# of netsD 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/drive/My Drive/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "errD0: 0.90 errD1: 0.68 errD2: 0.58 \n",
            "g_loss0: 6.51 g_loss1: 10.78 g_loss2: 11.97 w_loss: 31.14 s_loss: 29.29 kl_loss: 0.01 \n",
            "errD0: 0.64 errD1: 0.64 errD2: 1.42 \n",
            "g_loss0: 9.87 g_loss1: 8.99 g_loss2: 1.44 w_loss: 26.43 s_loss: 26.54 kl_loss: 0.01 \n",
            "errD0: 0.64 errD1: 0.62 errD2: 1.03 \n",
            "g_loss0: 8.00 g_loss1: 6.57 g_loss2: 5.14 w_loss: 25.17 s_loss: 26.13 kl_loss: 0.01 \n",
            "errD0: 0.73 errD1: 0.78 errD2: 0.83 \n",
            "g_loss0: 10.06 g_loss1: 7.74 g_loss2: 7.38 w_loss: 27.82 s_loss: 23.44 kl_loss: 0.01 \n",
            "[0/200][442]\n",
            "                  Loss_D: 3.68 Loss_G: 86.32 Time: 1102.40s\n",
            "Save G/Ds models.\n",
            "errD0: 0.74 errD1: 0.63 errD2: 0.66 \n",
            "g_loss0: 5.91 g_loss1: 10.92 g_loss2: 8.01 w_loss: 24.38 s_loss: 25.57 kl_loss: 0.01 \n",
            "errD0: 0.64 errD1: 0.78 errD2: 0.48 \n",
            "g_loss0: 8.92 g_loss1: 10.34 g_loss2: 11.66 w_loss: 19.62 s_loss: 23.92 kl_loss: 0.02 \n",
            "errD0: 0.56 errD1: 0.58 errD2: 0.61 \n",
            "g_loss0: 10.32 g_loss1: 7.91 g_loss2: 8.93 w_loss: 19.25 s_loss: 24.15 kl_loss: 0.01 \n",
            "errD0: 0.61 errD1: 0.67 errD2: 0.64 \n",
            "g_loss0: 7.55 g_loss1: 4.30 g_loss2: 7.03 w_loss: 20.41 s_loss: 23.92 kl_loss: 0.02 \n",
            "[1/200][442]\n",
            "                  Loss_D: 2.11 Loss_G: 65.26 Time: 189.36s\n",
            "errD0: 1.32 errD1: 0.65 errD2: 1.29 \n",
            "g_loss0: 1.87 g_loss1: 9.01 g_loss2: 2.68 w_loss: 18.18 s_loss: 23.60 kl_loss: 0.02 \n",
            "errD0: 0.67 errD1: 0.76 errD2: 0.93 \n",
            "g_loss0: 7.51 g_loss1: 2.76 g_loss2: 10.40 w_loss: 18.63 s_loss: 21.46 kl_loss: 0.02 \n",
            "errD0: 0.80 errD1: 0.43 errD2: 2.89 \n",
            "g_loss0: 9.96 g_loss1: 9.95 g_loss2: 1.02 w_loss: 18.27 s_loss: 20.27 kl_loss: 0.02 \n",
            "errD0: 0.61 errD1: 0.76 errD2: 0.56 \n",
            "g_loss0: 12.95 g_loss1: 5.99 g_loss2: 11.49 w_loss: 19.45 s_loss: 22.95 kl_loss: 0.04 \n",
            "errD0: 0.40 errD1: 0.75 errD2: 0.78 \n",
            "g_loss0: 10.58 g_loss1: 6.76 g_loss2: 3.81 w_loss: 14.90 s_loss: 21.44 kl_loss: 0.03 \n",
            "[2/200][442]\n",
            "                  Loss_D: 1.74 Loss_G: 57.82 Time: 232.94s\n",
            "errD0: 1.46 errD1: 0.61 errD2: 0.99 \n",
            "g_loss0: 0.17 g_loss1: 7.89 g_loss2: 2.43 w_loss: 12.89 s_loss: 22.71 kl_loss: 0.03 \n",
            "errD0: 0.52 errD1: 0.56 errD2: 1.03 \n",
            "g_loss0: 11.48 g_loss1: 8.94 g_loss2: 2.22 w_loss: 15.82 s_loss: 20.64 kl_loss: 0.04 \n",
            "errD0: 0.55 errD1: 0.99 errD2: 0.57 \n",
            "g_loss0: 9.76 g_loss1: 4.69 g_loss2: 6.83 w_loss: 14.07 s_loss: 18.15 kl_loss: 0.04 \n",
            "errD0: 0.57 errD1: 0.50 errD2: 2.57 \n",
            "g_loss0: 4.61 g_loss1: 7.50 g_loss2: 0.36 w_loss: 16.08 s_loss: 19.81 kl_loss: 0.04 \n",
            "[3/200][442]\n",
            "                  Loss_D: 1.98 Loss_G: 56.18 Time: 189.14s\n",
            "errD0: 0.72 errD1: 0.69 errD2: 1.05 \n",
            "g_loss0: 12.87 g_loss1: 9.66 g_loss2: 4.71 w_loss: 15.70 s_loss: 19.88 kl_loss: 0.06 \n",
            "errD0: 0.35 errD1: 0.72 errD2: 0.62 \n",
            "g_loss0: 9.24 g_loss1: 6.08 g_loss2: 8.72 w_loss: 16.08 s_loss: 21.19 kl_loss: 0.05 \n",
            "errD0: 0.30 errD1: 0.73 errD2: 1.23 \n",
            "g_loss0: 9.70 g_loss1: 8.33 g_loss2: 8.81 w_loss: 15.27 s_loss: 19.68 kl_loss: 0.07 \n",
            "errD0: 0.36 errD1: 0.95 errD2: 1.05 \n",
            "g_loss0: 12.01 g_loss1: 9.50 g_loss2: 6.98 w_loss: 15.03 s_loss: 19.63 kl_loss: 0.09 \n",
            "errD0: 5.86 errD1: 0.57 errD2: 0.66 \n",
            "g_loss0: 1.10 g_loss1: 8.24 g_loss2: 7.95 w_loss: 12.20 s_loss: 17.12 kl_loss: 0.06 \n",
            "[4/200][442]\n",
            "                  Loss_D: 2.25 Loss_G: 61.31 Time: 228.03s\n",
            "errD0: 0.57 errD1: 0.65 errD2: 0.27 \n",
            "g_loss0: 8.50 g_loss1: 8.58 g_loss2: 9.01 w_loss: 12.47 s_loss: 19.29 kl_loss: 0.08 \n",
            "errD0: 0.74 errD1: 0.47 errD2: 0.36 \n",
            "g_loss0: 10.50 g_loss1: 7.63 g_loss2: 5.97 w_loss: 16.31 s_loss: 20.00 kl_loss: 0.10 \n",
            "errD0: 1.18 errD1: 1.80 errD2: 1.03 \n",
            "g_loss0: 19.09 g_loss1: 20.05 g_loss2: 3.21 w_loss: 14.95 s_loss: 19.85 kl_loss: 0.11 \n",
            "errD0: 0.64 errD1: 1.05 errD2: 1.20 \n",
            "g_loss0: 9.00 g_loss1: 17.33 g_loss2: 19.36 w_loss: 16.76 s_loss: 18.70 kl_loss: 0.08 \n",
            "[5/200][442]\n",
            "                  Loss_D: 1.98 Loss_G: 58.48 Time: 188.46s\n",
            "errD0: 0.59 errD1: 0.72 errD2: 1.30 \n",
            "g_loss0: 7.32 g_loss1: 7.26 g_loss2: 1.74 w_loss: 8.67 s_loss: 16.88 kl_loss: 0.09 \n",
            "errD0: 0.94 errD1: 0.94 errD2: 0.98 \n",
            "g_loss0: 6.28 g_loss1: 5.30 g_loss2: 2.81 w_loss: 10.08 s_loss: 18.06 kl_loss: 0.13 \n",
            "errD0: 0.65 errD1: 0.62 errD2: 0.69 \n",
            "g_loss0: 10.04 g_loss1: 10.32 g_loss2: 7.96 w_loss: 16.33 s_loss: 20.33 kl_loss: 0.13 \n",
            "errD0: 0.69 errD1: 2.82 errD2: 0.94 \n",
            "g_loss0: 9.21 g_loss1: 4.77 g_loss2: 5.98 w_loss: 14.56 s_loss: 17.76 kl_loss: 0.09 \n",
            "[6/200][442]\n",
            "                  Loss_D: 2.25 Loss_G: 52.65 Time: 226.05s\n",
            "errD0: 1.18 errD1: 0.87 errD2: 0.66 \n",
            "g_loss0: 5.94 g_loss1: 3.99 g_loss2: 8.20 w_loss: 15.55 s_loss: 21.44 kl_loss: 0.13 \n",
            "errD0: 0.61 errD1: 1.59 errD2: 0.66 \n",
            "g_loss0: 3.59 g_loss1: 8.82 g_loss2: 8.89 w_loss: 10.98 s_loss: 16.04 kl_loss: 0.13 \n",
            "errD0: 0.46 errD1: 1.07 errD2: 1.42 \n",
            "g_loss0: 7.07 g_loss1: 4.64 g_loss2: 4.47 w_loss: 14.30 s_loss: 19.68 kl_loss: 0.16 \n",
            "errD0: 0.88 errD1: 0.44 errD2: 0.62 \n",
            "g_loss0: 2.00 g_loss1: 10.76 g_loss2: 7.14 w_loss: 13.35 s_loss: 19.41 kl_loss: 0.15 \n",
            "errD0: 0.58 errD1: 0.53 errD2: 0.68 \n",
            "g_loss0: 10.48 g_loss1: 8.81 g_loss2: 15.43 w_loss: 11.63 s_loss: 19.47 kl_loss: 0.11 \n",
            "[7/200][442]\n",
            "                  Loss_D: 2.56 Loss_G: 63.24 Time: 188.54s\n",
            "errD0: 0.48 errD1: 0.74 errD2: 0.68 \n",
            "g_loss0: 5.94 g_loss1: 7.92 g_loss2: 13.40 w_loss: 11.63 s_loss: 17.87 kl_loss: 0.12 \n",
            "errD0: 0.46 errD1: 1.89 errD2: 0.77 \n",
            "g_loss0: 4.09 g_loss1: 11.02 g_loss2: 5.11 w_loss: 13.42 s_loss: 19.41 kl_loss: 0.17 \n",
            "errD0: 0.52 errD1: 0.82 errD2: 0.65 \n",
            "g_loss0: 14.46 g_loss1: 12.50 g_loss2: 7.17 w_loss: 9.50 s_loss: 14.74 kl_loss: 0.11 \n",
            "errD0: 0.40 errD1: 0.50 errD2: 1.54 \n",
            "g_loss0: 7.86 g_loss1: 4.63 g_loss2: 1.78 w_loss: 11.40 s_loss: 16.23 kl_loss: 0.17 \n",
            "[8/200][442]\n",
            "                  Loss_D: 2.45 Loss_G: 57.50 Time: 188.81s\n",
            "errD0: 0.72 errD1: 0.42 errD2: 1.70 \n",
            "g_loss0: 4.99 g_loss1: 11.00 g_loss2: 1.01 w_loss: 14.60 s_loss: 16.87 kl_loss: 0.14 \n",
            "errD0: 0.69 errD1: 0.85 errD2: 0.64 \n",
            "g_loss0: 7.85 g_loss1: 8.48 g_loss2: 4.83 w_loss: 10.96 s_loss: 18.41 kl_loss: 0.13 \n",
            "errD0: 0.53 errD1: 1.73 errD2: 0.62 \n",
            "g_loss0: 7.75 g_loss1: 0.84 g_loss2: 5.19 w_loss: 12.61 s_loss: 19.23 kl_loss: 0.14 \n",
            "errD0: 0.73 errD1: 0.56 errD2: 1.02 \n",
            "g_loss0: 4.22 g_loss1: 7.47 g_loss2: 6.58 w_loss: 12.41 s_loss: 17.97 kl_loss: 0.22 \n",
            "errD0: 0.38 errD1: 0.35 errD2: 0.64 \n",
            "g_loss0: 9.80 g_loss1: 9.59 g_loss2: 7.36 w_loss: 12.07 s_loss: 17.73 kl_loss: 0.11 \n",
            "[9/200][442]\n",
            "                  Loss_D: 1.89 Loss_G: 48.21 Time: 227.54s\n",
            "errD0: 0.88 errD1: 0.53 errD2: 1.03 \n",
            "g_loss0: 1.41 g_loss1: 10.06 g_loss2: 8.98 w_loss: 12.13 s_loss: 19.57 kl_loss: 0.18 \n",
            "errD0: 0.82 errD1: 0.65 errD2: 0.77 \n",
            "g_loss0: 13.51 g_loss1: 12.05 g_loss2: 4.27 w_loss: 11.95 s_loss: 18.04 kl_loss: 0.17 \n",
            "errD0: 0.84 errD1: 0.59 errD2: 1.28 \n",
            "g_loss0: 11.71 g_loss1: 5.81 g_loss2: 7.96 w_loss: 14.44 s_loss: 19.50 kl_loss: 0.14 \n",
            "errD0: 0.41 errD1: 0.63 errD2: 0.49 \n",
            "g_loss0: 7.46 g_loss1: 12.76 g_loss2: 8.37 w_loss: 9.55 s_loss: 18.72 kl_loss: 0.12 \n",
            "[10/200][442]\n",
            "                  Loss_D: 3.04 Loss_G: 53.50 Time: 188.63s\n",
            "errD0: 0.74 errD1: 0.47 errD2: 0.82 \n",
            "g_loss0: 15.29 g_loss1: 9.79 g_loss2: 20.05 w_loss: 11.62 s_loss: 15.71 kl_loss: 0.16 \n",
            "errD0: 0.27 errD1: 0.42 errD2: 0.60 \n",
            "g_loss0: 8.82 g_loss1: 8.66 g_loss2: 4.53 w_loss: 12.25 s_loss: 19.66 kl_loss: 0.15 \n",
            "errD0: 0.65 errD1: 0.89 errD2: 1.08 \n",
            "g_loss0: 13.66 g_loss1: 18.94 g_loss2: 4.71 w_loss: 14.09 s_loss: 17.80 kl_loss: 0.17 \n",
            "errD0: 0.61 errD1: 0.79 errD2: 0.62 \n",
            "g_loss0: 11.78 g_loss1: 11.20 g_loss2: 11.42 w_loss: 12.77 s_loss: 17.69 kl_loss: 0.16 \n",
            "errD0: 0.50 errD1: 1.24 errD2: 0.74 \n",
            "g_loss0: 9.58 g_loss1: 10.08 g_loss2: 8.60 w_loss: 9.35 s_loss: 19.25 kl_loss: 0.20 \n",
            "[11/200][442]\n",
            "                  Loss_D: 2.10 Loss_G: 49.93 Time: 228.49s\n",
            "errD0: 0.30 errD1: 0.33 errD2: 0.89 \n",
            "g_loss0: 11.60 g_loss1: 6.61 g_loss2: 3.30 w_loss: 10.16 s_loss: 17.34 kl_loss: 0.15 \n",
            "errD0: 0.40 errD1: 0.66 errD2: 0.68 \n",
            "g_loss0: 10.12 g_loss1: 9.66 g_loss2: 6.17 w_loss: 9.93 s_loss: 18.56 kl_loss: 0.14 \n",
            "errD0: 1.18 errD1: 0.42 errD2: 0.74 \n",
            "g_loss0: 0.43 g_loss1: 10.45 g_loss2: 7.18 w_loss: 10.47 s_loss: 17.17 kl_loss: 0.16 \n",
            "errD0: 0.41 errD1: 0.31 errD2: 0.81 \n",
            "g_loss0: 8.23 g_loss1: 9.28 g_loss2: 6.05 w_loss: 8.17 s_loss: 16.01 kl_loss: 0.17 \n",
            "[12/200][442]\n",
            "                  Loss_D: 2.12 Loss_G: 52.62 Time: 188.50s\n",
            "errD0: 0.48 errD1: 0.63 errD2: 0.50 \n",
            "g_loss0: 5.71 g_loss1: 14.12 g_loss2: 15.39 w_loss: 13.23 s_loss: 17.21 kl_loss: 0.14 \n",
            "errD0: 0.40 errD1: 0.51 errD2: 1.01 \n",
            "g_loss0: 10.18 g_loss1: 9.77 g_loss2: 3.31 w_loss: 9.66 s_loss: 19.52 kl_loss: 0.18 \n",
            "errD0: 0.66 errD1: 0.43 errD2: 2.24 \n",
            "g_loss0: 13.10 g_loss1: 17.35 g_loss2: 0.26 w_loss: 10.77 s_loss: 15.91 kl_loss: 0.17 \n",
            "errD0: 0.68 errD1: 0.90 errD2: 0.69 \n",
            "g_loss0: 8.33 g_loss1: 6.67 g_loss2: 6.30 w_loss: 7.93 s_loss: 15.08 kl_loss: 0.18 \n",
            "[13/200][442]\n",
            "                  Loss_D: 1.54 Loss_G: 60.21 Time: 225.27s\n",
            "errD0: 0.33 errD1: 0.45 errD2: 0.67 \n",
            "g_loss0: 7.73 g_loss1: 7.79 g_loss2: 9.64 w_loss: 7.09 s_loss: 15.46 kl_loss: 0.15 \n",
            "errD0: 0.20 errD1: 0.23 errD2: 0.52 \n",
            "g_loss0: 8.52 g_loss1: 13.06 g_loss2: 9.78 w_loss: 9.77 s_loss: 14.43 kl_loss: 0.16 \n",
            "errD0: 0.56 errD1: 0.50 errD2: 0.83 \n",
            "g_loss0: 4.38 g_loss1: 4.88 g_loss2: 13.08 w_loss: 10.50 s_loss: 17.00 kl_loss: 0.14 \n",
            "errD0: 0.73 errD1: 0.54 errD2: 0.84 \n",
            "g_loss0: 12.07 g_loss1: 9.90 g_loss2: 8.20 w_loss: 14.24 s_loss: 20.17 kl_loss: 0.17 \n",
            "errD0: 0.14 errD1: 0.68 errD2: 0.50 \n",
            "g_loss0: 10.42 g_loss1: 15.58 g_loss2: 10.14 w_loss: 8.85 s_loss: 17.05 kl_loss: 0.19 \n",
            "[14/200][442]\n",
            "                  Loss_D: 1.64 Loss_G: 44.61 Time: 188.59s\n",
            "errD0: 0.44 errD1: 0.75 errD2: 0.71 \n",
            "g_loss0: 11.51 g_loss1: 12.53 g_loss2: 4.92 w_loss: 11.88 s_loss: 17.96 kl_loss: 0.20 \n",
            "errD0: 0.48 errD1: 0.60 errD2: 0.30 \n",
            "g_loss0: 11.58 g_loss1: 8.97 g_loss2: 12.76 w_loss: 10.17 s_loss: 16.35 kl_loss: 0.16 \n",
            "errD0: 0.35 errD1: 0.78 errD2: 0.89 \n",
            "g_loss0: 8.57 g_loss1: 1.60 g_loss2: 4.03 w_loss: 13.57 s_loss: 17.12 kl_loss: 0.20 \n",
            "errD0: 1.13 errD1: 0.43 errD2: 0.84 \n",
            "g_loss0: 16.95 g_loss1: 11.95 g_loss2: 9.17 w_loss: 11.40 s_loss: 19.61 kl_loss: 0.24 \n",
            "[15/200][442]\n",
            "                  Loss_D: 2.05 Loss_G: 72.83 Time: 228.86s\n",
            "errD0: 0.55 errD1: 0.53 errD2: 0.76 \n",
            "g_loss0: 8.34 g_loss1: 9.13 g_loss2: 14.46 w_loss: 9.69 s_loss: 17.85 kl_loss: 0.20 \n",
            "errD0: 1.83 errD1: 0.51 errD2: 0.69 \n",
            "g_loss0: 10.52 g_loss1: 8.77 g_loss2: 6.81 w_loss: 11.87 s_loss: 17.12 kl_loss: 0.16 \n",
            "errD0: 0.29 errD1: 0.36 errD2: 0.46 \n",
            "g_loss0: 8.22 g_loss1: 5.76 g_loss2: 8.76 w_loss: 11.23 s_loss: 18.52 kl_loss: 0.21 \n",
            "errD0: 0.26 errD1: 0.25 errD2: 0.68 \n",
            "g_loss0: 9.19 g_loss1: 13.88 g_loss2: 7.48 w_loss: 10.58 s_loss: 16.61 kl_loss: 0.21 \n",
            "errD0: 0.67 errD1: 0.93 errD2: 0.78 \n",
            "g_loss0: 9.68 g_loss1: 13.56 g_loss2: 19.19 w_loss: 14.61 s_loss: 19.87 kl_loss: 0.20 \n",
            "[16/200][442]\n",
            "                  Loss_D: 1.66 Loss_G: 60.44 Time: 188.99s\n",
            "errD0: 0.35 errD1: 0.33 errD2: 0.65 \n",
            "g_loss0: 10.80 g_loss1: 11.03 g_loss2: 8.97 w_loss: 9.41 s_loss: 16.38 kl_loss: 0.16 \n",
            "errD0: 2.21 errD1: 0.47 errD2: 1.22 \n",
            "g_loss0: 4.95 g_loss1: 10.69 g_loss2: 6.28 w_loss: 16.13 s_loss: 21.28 kl_loss: 0.20 \n",
            "errD0: 0.34 errD1: 0.62 errD2: 0.60 \n",
            "g_loss0: 8.63 g_loss1: 19.50 g_loss2: 8.77 w_loss: 11.32 s_loss: 17.29 kl_loss: 0.20 \n",
            "errD0: 0.32 errD1: 0.29 errD2: 0.61 \n",
            "g_loss0: 9.20 g_loss1: 9.39 g_loss2: 7.41 w_loss: 9.17 s_loss: 15.65 kl_loss: 0.23 \n",
            "[17/200][442]\n",
            "                  Loss_D: 1.03 Loss_G: 61.74 Time: 189.26s\n",
            "errD0: 0.12 errD1: 0.76 errD2: 0.85 \n",
            "g_loss0: 10.85 g_loss1: 11.86 g_loss2: 1.44 w_loss: 10.55 s_loss: 18.10 kl_loss: 0.21 \n",
            "errD0: 0.42 errD1: 0.53 errD2: 0.50 \n",
            "g_loss0: 13.23 g_loss1: 11.05 g_loss2: 10.07 w_loss: 8.86 s_loss: 21.02 kl_loss: 0.15 \n",
            "errD0: 0.50 errD1: 0.61 errD2: 0.74 \n",
            "g_loss0: 15.12 g_loss1: 13.93 g_loss2: 6.82 w_loss: 10.81 s_loss: 16.30 kl_loss: 0.20 \n",
            "errD0: 0.26 errD1: 0.58 errD2: 2.61 \n",
            "g_loss0: 7.01 g_loss1: 16.76 g_loss2: 1.56 w_loss: 11.23 s_loss: 18.13 kl_loss: 0.20 \n",
            "[18/200][442]\n",
            "                  Loss_D: 2.22 Loss_G: 57.02 Time: 228.54s\n",
            "errD0: 0.11 errD1: 0.22 errD2: 0.68 \n",
            "g_loss0: 12.08 g_loss1: 12.22 g_loss2: 6.40 w_loss: 12.58 s_loss: 18.18 kl_loss: 0.17 \n",
            "errD0: 0.52 errD1: 0.38 errD2: 1.13 \n",
            "g_loss0: 10.41 g_loss1: 14.10 g_loss2: 1.98 w_loss: 9.39 s_loss: 15.67 kl_loss: 0.22 \n",
            "errD0: 0.19 errD1: 0.24 errD2: 0.44 \n",
            "g_loss0: 11.39 g_loss1: 11.66 g_loss2: 3.39 w_loss: 10.22 s_loss: 15.51 kl_loss: 0.22 \n",
            "errD0: 0.24 errD1: 0.39 errD2: 1.27 \n",
            "g_loss0: 8.52 g_loss1: 6.48 g_loss2: 6.24 w_loss: 14.80 s_loss: 17.77 kl_loss: 0.19 \n",
            "errD0: 1.00 errD1: 0.30 errD2: 0.53 \n",
            "g_loss0: 5.85 g_loss1: 10.10 g_loss2: 9.75 w_loss: 10.39 s_loss: 18.98 kl_loss: 0.20 \n",
            "[19/200][442]\n",
            "                  Loss_D: 0.97 Loss_G: 51.53 Time: 189.06s\n",
            "errD0: 0.81 errD1: 0.75 errD2: 0.73 \n",
            "g_loss0: 12.35 g_loss1: 11.42 g_loss2: 7.84 w_loss: 13.58 s_loss: 17.56 kl_loss: 0.26 \n",
            "errD0: 0.22 errD1: 0.18 errD2: 0.75 \n",
            "g_loss0: 8.57 g_loss1: 13.11 g_loss2: 20.70 w_loss: 11.12 s_loss: 17.87 kl_loss: 0.19 \n",
            "errD0: 0.30 errD1: 0.55 errD2: 0.64 \n",
            "g_loss0: 18.58 g_loss1: 13.05 g_loss2: 4.56 w_loss: 10.08 s_loss: 17.40 kl_loss: 0.19 \n",
            "errD0: 0.24 errD1: 0.25 errD2: 0.43 \n",
            "g_loss0: 11.77 g_loss1: 11.82 g_loss2: 14.76 w_loss: 12.14 s_loss: 17.17 kl_loss: 0.20 \n",
            "[20/200][442]\n",
            "                  Loss_D: 1.72 Loss_G: 47.37 Time: 229.50s\n",
            "errD0: 0.48 errD1: 0.60 errD2: 0.87 \n",
            "g_loss0: 11.19 g_loss1: 10.85 g_loss2: 5.57 w_loss: 9.87 s_loss: 15.79 kl_loss: 0.18 \n",
            "errD0: 1.35 errD1: 1.08 errD2: 1.44 \n",
            "g_loss0: 6.26 g_loss1: 8.80 g_loss2: 6.10 w_loss: 12.34 s_loss: 17.12 kl_loss: 0.25 \n",
            "errD0: 0.14 errD1: 1.59 errD2: 0.73 \n",
            "g_loss0: 8.98 g_loss1: 18.53 g_loss2: 7.86 w_loss: 13.43 s_loss: 17.25 kl_loss: 0.26 \n",
            "errD0: 0.17 errD1: 0.34 errD2: 0.17 \n",
            "g_loss0: 10.20 g_loss1: 6.48 g_loss2: 8.10 w_loss: 10.29 s_loss: 17.08 kl_loss: 0.22 \n",
            "errD0: 1.39 errD1: 0.40 errD2: 0.27 \n",
            "g_loss0: 13.80 g_loss1: 4.74 g_loss2: 9.44 w_loss: 9.88 s_loss: 18.20 kl_loss: 0.23 \n",
            "[21/200][442]\n",
            "                  Loss_D: 1.59 Loss_G: 63.49 Time: 189.43s\n",
            "errD0: 0.26 errD1: 0.26 errD2: 0.56 \n",
            "g_loss0: 7.22 g_loss1: 15.12 g_loss2: 9.41 w_loss: 15.33 s_loss: 18.30 kl_loss: 0.25 \n",
            "errD0: 0.08 errD1: 0.28 errD2: 0.29 \n",
            "g_loss0: 12.91 g_loss1: 7.42 g_loss2: 9.48 w_loss: 10.26 s_loss: 19.45 kl_loss: 0.24 \n",
            "errD0: 0.39 errD1: 0.47 errD2: 0.90 \n",
            "g_loss0: 3.67 g_loss1: 15.37 g_loss2: 4.83 w_loss: 11.71 s_loss: 18.45 kl_loss: 0.21 \n",
            "errD0: 0.28 errD1: 0.48 errD2: 1.77 \n",
            "g_loss0: 8.69 g_loss1: 18.77 g_loss2: 6.38 w_loss: 11.81 s_loss: 14.22 kl_loss: 0.22 \n",
            "[22/200][442]\n",
            "                  Loss_D: 1.45 Loss_G: 63.45 Time: 228.11s\n",
            "errD0: 0.57 errD1: 0.57 errD2: 0.28 \n",
            "g_loss0: 8.47 g_loss1: 4.66 g_loss2: 9.66 w_loss: 13.83 s_loss: 18.86 kl_loss: 0.20 \n",
            "errD0: 1.88 errD1: 1.02 errD2: 0.69 \n",
            "g_loss0: 2.92 g_loss1: 18.83 g_loss2: 9.85 w_loss: 8.59 s_loss: 15.25 kl_loss: 0.24 \n",
            "errD0: 0.12 errD1: 0.09 errD2: 0.42 \n",
            "g_loss0: 13.42 g_loss1: 17.11 g_loss2: 11.96 w_loss: 13.54 s_loss: 17.46 kl_loss: 0.25 \n",
            "errD0: 0.25 errD1: 0.55 errD2: 1.03 \n",
            "g_loss0: 12.47 g_loss1: 6.60 g_loss2: 21.33 w_loss: 12.75 s_loss: 17.56 kl_loss: 0.21 \n",
            "errD0: 1.73 errD1: 1.08 errD2: 1.70 \n",
            "g_loss0: 15.57 g_loss1: 8.52 g_loss2: 0.69 w_loss: 10.02 s_loss: 18.30 kl_loss: 0.21 \n",
            "[23/200][442]\n",
            "                  Loss_D: 1.96 Loss_G: 60.16 Time: 189.43s\n",
            "errD0: 0.19 errD1: 0.38 errD2: 0.72 \n",
            "g_loss0: 10.91 g_loss1: 13.16 g_loss2: 13.67 w_loss: 15.35 s_loss: 17.50 kl_loss: 0.28 \n",
            "errD0: 0.45 errD1: 0.49 errD2: 0.25 \n",
            "g_loss0: 10.23 g_loss1: 10.60 g_loss2: 12.83 w_loss: 12.17 s_loss: 18.49 kl_loss: 0.29 \n",
            "errD0: 0.12 errD1: 0.22 errD2: 0.39 \n",
            "g_loss0: 8.55 g_loss1: 8.38 g_loss2: 7.89 w_loss: 7.58 s_loss: 15.03 kl_loss: 0.22 \n",
            "errD0: 0.49 errD1: 0.30 errD2: 0.69 \n",
            "g_loss0: 8.54 g_loss1: 6.50 g_loss2: 11.66 w_loss: 14.14 s_loss: 18.78 kl_loss: 0.26 \n",
            "[24/200][442]\n",
            "                  Loss_D: 4.55 Loss_G: 54.26 Time: 231.34s\n",
            "errD0: 0.23 errD1: 0.46 errD2: 0.63 \n",
            "g_loss0: 8.11 g_loss1: 13.40 g_loss2: 6.93 w_loss: 15.67 s_loss: 19.47 kl_loss: 0.28 \n",
            "errD0: 0.54 errD1: 1.01 errD2: 0.82 \n",
            "g_loss0: 6.09 g_loss1: 8.07 g_loss2: 6.02 w_loss: 9.11 s_loss: 17.20 kl_loss: 0.22 \n",
            "errD0: 0.96 errD1: 0.39 errD2: 1.41 \n",
            "g_loss0: 4.22 g_loss1: 14.60 g_loss2: 4.04 w_loss: 13.33 s_loss: 19.37 kl_loss: 0.25 \n",
            "errD0: 0.31 errD1: 0.53 errD2: 0.57 \n",
            "g_loss0: 3.75 g_loss1: 4.11 g_loss2: 11.95 w_loss: 10.28 s_loss: 18.16 kl_loss: 0.25 \n",
            "[25/200][442]\n",
            "                  Loss_D: 1.33 Loss_G: 58.43 Time: 189.55s\n",
            "errD0: 0.08 errD1: 0.18 errD2: 0.27 \n",
            "g_loss0: 9.92 g_loss1: 14.06 g_loss2: 8.86 w_loss: 13.73 s_loss: 18.23 kl_loss: 0.25 \n",
            "errD0: 1.07 errD1: 0.63 errD2: 0.82 \n",
            "g_loss0: 17.49 g_loss1: 12.25 g_loss2: 3.68 w_loss: 7.36 s_loss: 16.28 kl_loss: 0.32 \n",
            "errD0: 0.25 errD1: 0.31 errD2: 0.42 \n",
            "g_loss0: 10.26 g_loss1: 7.10 g_loss2: 5.60 w_loss: 13.89 s_loss: 17.61 kl_loss: 0.29 \n",
            "errD0: 0.29 errD1: 0.44 errD2: 0.40 \n",
            "g_loss0: 8.95 g_loss1: 12.49 g_loss2: 6.46 w_loss: 11.41 s_loss: 18.94 kl_loss: 0.29 \n",
            "errD0: 0.25 errD1: 0.94 errD2: 0.68 \n",
            "g_loss0: 10.26 g_loss1: 18.36 g_loss2: 5.02 w_loss: 11.90 s_loss: 18.63 kl_loss: 0.31 \n",
            "[26/200][442]\n",
            "                  Loss_D: 2.07 Loss_G: 57.88 Time: 189.77s\n",
            "errD0: 0.47 errD1: 0.63 errD2: 0.67 \n",
            "g_loss0: 5.28 g_loss1: 10.83 g_loss2: 8.27 w_loss: 12.06 s_loss: 19.33 kl_loss: 0.30 \n",
            "errD0: 0.40 errD1: 0.36 errD2: 0.49 \n",
            "g_loss0: 12.78 g_loss1: 10.13 g_loss2: 7.72 w_loss: 17.03 s_loss: 20.16 kl_loss: 0.30 \n",
            "errD0: 0.29 errD1: 0.32 errD2: 0.54 \n",
            "g_loss0: 16.25 g_loss1: 16.81 g_loss2: 16.83 w_loss: 11.43 s_loss: 16.00 kl_loss: 0.22 \n",
            "errD0: 0.08 errD1: 0.30 errD2: 0.31 \n",
            "g_loss0: 10.26 g_loss1: 9.18 g_loss2: 13.38 w_loss: 8.42 s_loss: 16.14 kl_loss: 0.25 \n",
            "[27/200][442]\n",
            "                  Loss_D: 0.92 Loss_G: 65.92 Time: 229.70s\n",
            "errD0: 0.26 errD1: 1.29 errD2: 0.33 \n",
            "g_loss0: 11.31 g_loss1: 6.93 g_loss2: 11.19 w_loss: 12.93 s_loss: 18.03 kl_loss: 0.25 \n",
            "errD0: 0.39 errD1: 0.17 errD2: 1.54 \n",
            "g_loss0: 7.85 g_loss1: 12.32 g_loss2: 4.40 w_loss: 12.30 s_loss: 18.82 kl_loss: 0.35 \n",
            "errD0: 0.19 errD1: 0.29 errD2: 0.55 \n",
            "g_loss0: 10.92 g_loss1: 15.25 g_loss2: 7.03 w_loss: 10.84 s_loss: 20.11 kl_loss: 0.23 \n",
            "errD0: 0.56 errD1: 0.76 errD2: 0.78 \n",
            "g_loss0: 1.97 g_loss1: 15.88 g_loss2: 11.64 w_loss: 11.11 s_loss: 17.60 kl_loss: 0.27 \n",
            "errD0: 0.26 errD1: 0.19 errD2: 0.76 \n",
            "g_loss0: 9.50 g_loss1: 10.41 g_loss2: 9.23 w_loss: 14.60 s_loss: 16.34 kl_loss: 0.27 \n",
            "[28/200][442]\n",
            "                  Loss_D: 2.20 Loss_G: 61.53 Time: 189.33s\n",
            "errD0: 0.46 errD1: 0.31 errD2: 0.46 \n",
            "g_loss0: 11.44 g_loss1: 10.55 g_loss2: 7.56 w_loss: 11.80 s_loss: 16.47 kl_loss: 0.30 \n",
            "errD0: 0.62 errD1: 0.19 errD2: 0.17 \n",
            "g_loss0: 15.25 g_loss1: 4.41 g_loss2: 11.52 w_loss: 14.62 s_loss: 19.20 kl_loss: 0.24 \n",
            "errD0: 0.23 errD1: 0.73 errD2: 0.62 \n",
            "g_loss0: 10.90 g_loss1: 11.07 g_loss2: 9.35 w_loss: 15.10 s_loss: 18.85 kl_loss: 0.33 \n",
            "errD0: 1.47 errD1: 0.45 errD2: 0.73 \n",
            "g_loss0: 9.09 g_loss1: 7.75 g_loss2: 11.05 w_loss: 15.88 s_loss: 20.61 kl_loss: 0.35 \n",
            "[29/200][442]\n",
            "                  Loss_D: 1.65 Loss_G: 51.14 Time: 228.09s\n",
            "errD0: 0.37 errD1: 0.41 errD2: 0.35 \n",
            "g_loss0: 10.86 g_loss1: 12.45 g_loss2: 7.93 w_loss: 12.26 s_loss: 19.00 kl_loss: 0.25 \n",
            "errD0: 0.19 errD1: 0.15 errD2: 0.19 \n",
            "g_loss0: 10.79 g_loss1: 11.88 g_loss2: 10.44 w_loss: 11.97 s_loss: 17.95 kl_loss: 0.30 \n",
            "errD0: 0.39 errD1: 0.27 errD2: 0.61 \n",
            "g_loss0: 9.72 g_loss1: 10.43 g_loss2: 13.55 w_loss: 14.22 s_loss: 19.78 kl_loss: 0.40 \n",
            "errD0: 0.39 errD1: 0.19 errD2: 1.00 \n",
            "g_loss0: 4.10 g_loss1: 12.61 g_loss2: 0.31 w_loss: 8.27 s_loss: 16.00 kl_loss: 0.26 \n",
            "errD0: 0.10 errD1: 0.19 errD2: 0.60 \n",
            "g_loss0: 10.00 g_loss1: 19.94 g_loss2: 3.89 w_loss: 16.25 s_loss: 20.41 kl_loss: 0.35 \n",
            "[30/200][442]\n",
            "                  Loss_D: 1.20 Loss_G: 79.50 Time: 190.83s\n",
            "errD0: 0.66 errD1: 0.41 errD2: 0.32 \n",
            "g_loss0: 12.82 g_loss1: 10.99 g_loss2: 10.35 w_loss: 13.13 s_loss: 20.79 kl_loss: 0.28 \n",
            "errD0: 0.09 errD1: 0.97 errD2: 1.47 \n",
            "g_loss0: 8.40 g_loss1: 22.04 g_loss2: 7.81 w_loss: 12.55 s_loss: 15.78 kl_loss: 0.29 \n",
            "errD0: 0.40 errD1: 0.55 errD2: 0.23 \n",
            "g_loss0: 8.72 g_loss1: 16.20 g_loss2: 10.38 w_loss: 10.04 s_loss: 17.57 kl_loss: 0.29 \n",
            "errD0: 0.21 errD1: 0.70 errD2: 0.68 \n",
            "g_loss0: 12.30 g_loss1: 6.20 g_loss2: 17.66 w_loss: 11.07 s_loss: 18.90 kl_loss: 0.34 \n",
            "[31/200][442]\n",
            "                  Loss_D: 1.06 Loss_G: 69.44 Time: 227.62s\n",
            "errD0: 0.51 errD1: 0.72 errD2: 0.73 \n",
            "g_loss0: 6.68 g_loss1: 7.71 g_loss2: 3.33 w_loss: 12.38 s_loss: 19.60 kl_loss: 0.39 \n",
            "errD0: 0.30 errD1: 0.53 errD2: 1.24 \n",
            "g_loss0: 13.18 g_loss1: 10.73 g_loss2: 19.33 w_loss: 8.79 s_loss: 17.22 kl_loss: 0.27 \n",
            "errD0: 0.32 errD1: 0.69 errD2: 0.35 \n",
            "g_loss0: 8.02 g_loss1: 12.43 g_loss2: 5.03 w_loss: 15.94 s_loss: 16.52 kl_loss: 0.36 \n",
            "errD0: 0.42 errD1: 0.69 errD2: 0.35 \n",
            "g_loss0: 10.40 g_loss1: 1.43 g_loss2: 13.89 w_loss: 13.27 s_loss: 18.27 kl_loss: 0.27 \n",
            "[32/200][442]\n",
            "                  Loss_D: 3.68 Loss_G: 61.30 Time: 189.32s\n",
            "errD0: 0.23 errD1: 0.30 errD2: 0.33 \n",
            "g_loss0: 7.22 g_loss1: 12.57 g_loss2: 4.94 w_loss: 10.55 s_loss: 18.07 kl_loss: 0.36 \n",
            "errD0: 0.23 errD1: 0.92 errD2: 1.04 \n",
            "g_loss0: 6.83 g_loss1: 15.20 g_loss2: 1.66 w_loss: 15.47 s_loss: 19.00 kl_loss: 0.31 \n",
            "errD0: 0.34 errD1: 0.39 errD2: 0.87 \n",
            "g_loss0: 9.81 g_loss1: 7.07 g_loss2: 16.87 w_loss: 12.47 s_loss: 16.19 kl_loss: 0.26 \n",
            "errD0: 0.34 errD1: 0.73 errD2: 0.37 \n",
            "g_loss0: 5.80 g_loss1: 3.27 g_loss2: 9.01 w_loss: 12.35 s_loss: 19.04 kl_loss: 0.43 \n",
            "errD0: 1.77 errD1: 0.70 errD2: 0.62 \n",
            "g_loss0: 0.03 g_loss1: 4.08 g_loss2: 10.04 w_loss: 15.42 s_loss: 17.30 kl_loss: 0.29 \n",
            "[33/200][442]\n",
            "                  Loss_D: 1.42 Loss_G: 62.44 Time: 229.14s\n",
            "errD0: 0.76 errD1: 0.21 errD2: 0.33 \n",
            "g_loss0: 15.64 g_loss1: 9.76 g_loss2: 9.24 w_loss: 13.57 s_loss: 19.88 kl_loss: 0.37 \n",
            "errD0: 0.21 errD1: 0.32 errD2: 0.23 \n",
            "g_loss0: 10.58 g_loss1: 11.56 g_loss2: 8.41 w_loss: 15.50 s_loss: 19.03 kl_loss: 0.29 \n",
            "errD0: 0.42 errD1: 0.34 errD2: 0.94 \n",
            "g_loss0: 11.22 g_loss1: 18.17 g_loss2: 10.21 w_loss: 11.81 s_loss: 18.77 kl_loss: 0.38 \n",
            "errD0: 0.57 errD1: 0.15 errD2: 0.23 \n",
            "g_loss0: 5.65 g_loss1: 11.32 g_loss2: 10.31 w_loss: 9.31 s_loss: 19.35 kl_loss: 0.33 \n",
            "[34/200][442]\n",
            "                  Loss_D: 2.05 Loss_G: 50.12 Time: 189.71s\n",
            "errD0: 0.29 errD1: 0.33 errD2: 1.02 \n",
            "g_loss0: 14.64 g_loss1: 15.81 g_loss2: 1.82 w_loss: 12.95 s_loss: 17.76 kl_loss: 0.40 \n",
            "errD0: 0.20 errD1: 0.34 errD2: 1.11 \n",
            "g_loss0: 14.90 g_loss1: 13.56 g_loss2: 20.16 w_loss: 12.07 s_loss: 18.60 kl_loss: 0.29 \n",
            "errD0: 1.65 errD1: 1.78 errD2: 0.47 \n",
            "g_loss0: 18.20 g_loss1: 2.34 g_loss2: 12.22 w_loss: 10.37 s_loss: 18.73 kl_loss: 0.31 \n",
            "errD0: 0.50 errD1: 0.53 errD2: 0.37 \n",
            "g_loss0: 12.41 g_loss1: 6.76 g_loss2: 7.91 w_loss: 11.60 s_loss: 18.74 kl_loss: 0.29 \n",
            "errD0: 0.32 errD1: 0.31 errD2: 0.51 \n",
            "g_loss0: 14.16 g_loss1: 7.95 g_loss2: 6.14 w_loss: 12.78 s_loss: 18.88 kl_loss: 0.32 \n",
            "[35/200][442]\n",
            "                  Loss_D: 2.86 Loss_G: 70.78 Time: 189.43s\n",
            "errD0: 0.10 errD1: 0.12 errD2: 1.14 \n",
            "g_loss0: 12.30 g_loss1: 17.12 g_loss2: 3.59 w_loss: 14.59 s_loss: 19.12 kl_loss: 0.24 \n",
            "errD0: 1.06 errD1: 1.12 errD2: 0.43 \n",
            "g_loss0: 4.25 g_loss1: 5.21 g_loss2: 14.62 w_loss: 10.31 s_loss: 18.41 kl_loss: 0.30 \n",
            "errD0: 0.55 errD1: 1.16 errD2: 1.16 \n",
            "g_loss0: 13.63 g_loss1: 3.50 g_loss2: 10.10 w_loss: 13.10 s_loss: 20.01 kl_loss: 0.31 \n",
            "errD0: 0.19 errD1: 0.52 errD2: 0.74 \n",
            "g_loss0: 11.93 g_loss1: 17.50 g_loss2: 16.55 w_loss: 14.28 s_loss: 15.79 kl_loss: 0.38 \n",
            "[36/200][442]\n",
            "                  Loss_D: 1.20 Loss_G: 56.25 Time: 228.84s\n",
            "errD0: 0.91 errD1: 1.12 errD2: 0.56 \n",
            "g_loss0: 6.98 g_loss1: 3.78 g_loss2: 7.64 w_loss: 12.15 s_loss: 21.13 kl_loss: 0.39 \n",
            "errD0: 0.06 errD1: 0.12 errD2: 0.21 \n",
            "g_loss0: 11.85 g_loss1: 14.39 g_loss2: 9.46 w_loss: 14.56 s_loss: 21.93 kl_loss: 0.44 \n",
            "errD0: 0.20 errD1: 0.16 errD2: 0.34 \n",
            "g_loss0: 10.71 g_loss1: 12.34 g_loss2: 7.06 w_loss: 9.69 s_loss: 17.35 kl_loss: 0.30 \n",
            "errD0: 0.44 errD1: 0.52 errD2: 0.50 \n",
            "g_loss0: 10.12 g_loss1: 15.03 g_loss2: 14.61 w_loss: 12.87 s_loss: 21.74 kl_loss: 0.45 \n",
            "[37/200][442]\n",
            "                  Loss_D: 0.72 Loss_G: 62.93 Time: 189.62s\n",
            "errD0: 0.28 errD1: 1.00 errD2: 1.22 \n",
            "g_loss0: 19.46 g_loss1: 1.94 g_loss2: 11.73 w_loss: 14.48 s_loss: 19.02 kl_loss: 0.44 \n",
            "errD0: 0.23 errD1: 0.33 errD2: 0.41 \n",
            "g_loss0: 13.92 g_loss1: 13.27 g_loss2: 8.49 w_loss: 12.17 s_loss: 19.88 kl_loss: 0.42 \n",
            "errD0: 0.10 errD1: 0.13 errD2: 0.24 \n",
            "g_loss0: 10.83 g_loss1: 10.50 g_loss2: 14.27 w_loss: 14.79 s_loss: 19.29 kl_loss: 0.40 \n",
            "errD0: 0.18 errD1: 0.13 errD2: 0.35 \n",
            "g_loss0: 13.22 g_loss1: 15.29 g_loss2: 8.61 w_loss: 13.06 s_loss: 17.02 kl_loss: 0.43 \n",
            "errD0: 0.39 errD1: 0.32 errD2: 0.09 \n",
            "g_loss0: 7.58 g_loss1: 8.11 g_loss2: 12.32 w_loss: 13.70 s_loss: 18.25 kl_loss: 0.44 \n",
            "[38/200][442]\n",
            "                  Loss_D: 0.35 Loss_G: 58.93 Time: 227.56s\n",
            "errD0: 0.14 errD1: 0.78 errD2: 0.33 \n",
            "g_loss0: 12.90 g_loss1: 4.28 g_loss2: 14.45 w_loss: 11.39 s_loss: 19.34 kl_loss: 0.34 \n",
            "errD0: 0.14 errD1: 0.31 errD2: 0.45 \n",
            "g_loss0: 19.31 g_loss1: 7.65 g_loss2: 9.54 w_loss: 12.16 s_loss: 17.80 kl_loss: 0.43 \n",
            "errD0: 0.04 errD1: 0.20 errD2: 0.07 \n",
            "g_loss0: 12.22 g_loss1: 13.97 g_loss2: 14.06 w_loss: 11.62 s_loss: 16.35 kl_loss: 0.36 \n",
            "errD0: 0.36 errD1: 0.27 errD2: 0.19 \n",
            "g_loss0: 7.48 g_loss1: 11.27 g_loss2: 8.56 w_loss: 11.20 s_loss: 18.31 kl_loss: 0.41 \n",
            "[39/200][442]\n",
            "                  Loss_D: 0.38 Loss_G: 59.35 Time: 189.61s\n",
            "errD0: 0.60 errD1: 0.41 errD2: 0.52 \n",
            "g_loss0: 9.51 g_loss1: 14.42 g_loss2: 10.03 w_loss: 13.02 s_loss: 19.59 kl_loss: 0.34 \n",
            "errD0: 1.10 errD1: 0.48 errD2: 0.47 \n",
            "g_loss0: 7.21 g_loss1: 15.58 g_loss2: 12.90 w_loss: 11.82 s_loss: 17.59 kl_loss: 0.30 \n",
            "errD0: 0.14 errD1: 0.31 errD2: 0.64 \n",
            "g_loss0: 9.75 g_loss1: 4.75 g_loss2: 11.34 w_loss: 15.58 s_loss: 18.93 kl_loss: 0.32 \n",
            "errD0: 0.53 errD1: 0.27 errD2: 0.25 \n",
            "g_loss0: 4.97 g_loss1: 6.12 g_loss2: 4.64 w_loss: 17.45 s_loss: 18.53 kl_loss: 0.40 \n",
            "errD0: 0.26 errD1: 0.29 errD2: 0.32 \n",
            "g_loss0: 10.43 g_loss1: 9.96 g_loss2: 12.86 w_loss: 11.55 s_loss: 20.30 kl_loss: 0.35 \n",
            "[40/200][442]\n",
            "                  Loss_D: 2.32 Loss_G: 71.10 Time: 228.50s\n",
            "errD0: 0.18 errD1: 0.37 errD2: 0.80 \n",
            "g_loss0: 18.60 g_loss1: 10.55 g_loss2: 14.55 w_loss: 12.28 s_loss: 18.76 kl_loss: 0.35 \n",
            "errD0: 0.32 errD1: 1.53 errD2: 0.27 \n",
            "g_loss0: 10.17 g_loss1: 15.71 g_loss2: 18.06 w_loss: 12.46 s_loss: 19.68 kl_loss: 0.28 \n",
            "errD0: 0.16 errD1: 0.29 errD2: 0.44 \n",
            "g_loss0: 9.87 g_loss1: 12.34 g_loss2: 5.58 w_loss: 11.36 s_loss: 18.13 kl_loss: 0.38 \n",
            "errD0: 0.17 errD1: 0.25 errD2: 1.10 \n",
            "g_loss0: 13.23 g_loss1: 9.85 g_loss2: 19.65 w_loss: 13.90 s_loss: 19.31 kl_loss: 0.39 \n",
            "[41/200][442]\n",
            "                  Loss_D: 1.73 Loss_G: 53.14 Time: 190.23s\n",
            "errD0: 0.11 errD1: 0.73 errD2: 0.24 \n",
            "g_loss0: 8.21 g_loss1: 21.98 g_loss2: 10.19 w_loss: 10.71 s_loss: 17.68 kl_loss: 0.42 \n",
            "errD0: 0.05 errD1: 0.30 errD2: 0.77 \n",
            "g_loss0: 12.11 g_loss1: 6.62 g_loss2: 7.99 w_loss: 10.15 s_loss: 19.19 kl_loss: 0.28 \n",
            "errD0: 0.38 errD1: 0.19 errD2: 0.37 \n",
            "g_loss0: 13.77 g_loss1: 20.19 g_loss2: 16.51 w_loss: 14.23 s_loss: 19.71 kl_loss: 0.37 \n",
            "errD0: 1.53 errD1: 1.11 errD2: 0.31 \n",
            "g_loss0: 9.62 g_loss1: 8.99 g_loss2: 19.99 w_loss: 9.42 s_loss: 16.98 kl_loss: 0.40 \n",
            "errD0: 0.14 errD1: 0.59 errD2: 0.18 \n",
            "g_loss0: 11.67 g_loss1: 14.40 g_loss2: 6.00 w_loss: 11.39 s_loss: 18.80 kl_loss: 0.31 \n",
            "[42/200][442]\n",
            "                  Loss_D: 1.10 Loss_G: 75.94 Time: 230.03s\n",
            "errD0: 0.20 errD1: 0.36 errD2: 0.88 \n",
            "g_loss0: 8.96 g_loss1: 13.23 g_loss2: 8.72 w_loss: 12.53 s_loss: 17.54 kl_loss: 0.38 \n",
            "errD0: 0.40 errD1: 0.73 errD2: 1.54 \n",
            "g_loss0: 13.41 g_loss1: 13.70 g_loss2: 16.40 w_loss: 14.52 s_loss: 19.04 kl_loss: 0.48 \n",
            "errD0: 0.37 errD1: 0.13 errD2: 0.17 \n",
            "g_loss0: 11.44 g_loss1: 11.82 g_loss2: 7.15 w_loss: 15.47 s_loss: 17.45 kl_loss: 0.46 \n",
            "errD0: 0.22 errD1: 0.63 errD2: 0.76 \n",
            "g_loss0: 8.65 g_loss1: 2.75 g_loss2: 0.68 w_loss: 12.74 s_loss: 20.66 kl_loss: 0.40 \n",
            "[43/200][442]\n",
            "                  Loss_D: 1.98 Loss_G: 73.38 Time: 189.53s\n",
            "errD0: 0.77 errD1: 0.49 errD2: 2.14 \n",
            "g_loss0: 4.29 g_loss1: 19.45 g_loss2: 3.48 w_loss: 14.58 s_loss: 17.45 kl_loss: 0.34 \n",
            "errD0: 0.38 errD1: 0.62 errD2: 0.35 \n",
            "g_loss0: 14.83 g_loss1: 13.89 g_loss2: 9.80 w_loss: 12.81 s_loss: 18.71 kl_loss: 0.46 \n",
            "errD0: 0.27 errD1: 0.65 errD2: 0.14 \n",
            "g_loss0: 5.16 g_loss1: 1.72 g_loss2: 6.85 w_loss: 13.83 s_loss: 19.35 kl_loss: 0.35 \n",
            "errD0: 0.57 errD1: 0.36 errD2: 1.67 \n",
            "g_loss0: 10.17 g_loss1: 13.58 g_loss2: 6.93 w_loss: 13.56 s_loss: 17.30 kl_loss: 0.45 \n",
            "[44/200][442]\n",
            "                  Loss_D: 0.58 Loss_G: 69.13 Time: 189.60s\n",
            "errD0: 0.26 errD1: 0.88 errD2: 0.36 \n",
            "g_loss0: 17.12 g_loss1: 9.33 g_loss2: 25.36 w_loss: 10.95 s_loss: 17.09 kl_loss: 0.32 \n",
            "errD0: 0.30 errD1: 0.57 errD2: 0.64 \n",
            "g_loss0: 13.33 g_loss1: 9.38 g_loss2: 12.55 w_loss: 12.53 s_loss: 17.33 kl_loss: 0.46 \n",
            "errD0: 0.52 errD1: 0.54 errD2: 2.38 \n",
            "g_loss0: 10.62 g_loss1: 18.67 g_loss2: 1.84 w_loss: 13.01 s_loss: 18.70 kl_loss: 0.46 \n",
            "errD0: 0.93 errD1: 0.14 errD2: 0.21 \n",
            "g_loss0: 17.67 g_loss1: 17.67 g_loss2: 11.64 w_loss: 9.68 s_loss: 16.79 kl_loss: 0.37 \n",
            "errD0: 0.19 errD1: 0.14 errD2: 1.08 \n",
            "g_loss0: 10.52 g_loss1: 8.70 g_loss2: 2.63 w_loss: 11.28 s_loss: 19.05 kl_loss: 0.33 \n",
            "[45/200][442]\n",
            "                  Loss_D: 0.89 Loss_G: 66.93 Time: 228.77s\n",
            "errD0: 0.09 errD1: 0.29 errD2: 2.64 \n",
            "g_loss0: 14.24 g_loss1: 16.32 g_loss2: 1.24 w_loss: 11.15 s_loss: 17.76 kl_loss: 0.39 \n",
            "errD0: 0.27 errD1: 0.10 errD2: 0.16 \n",
            "g_loss0: 11.69 g_loss1: 12.44 g_loss2: 6.97 w_loss: 9.50 s_loss: 16.09 kl_loss: 0.32 \n",
            "errD0: 0.15 errD1: 0.21 errD2: 0.54 \n",
            "g_loss0: 21.33 g_loss1: 11.60 g_loss2: 13.40 w_loss: 16.20 s_loss: 20.45 kl_loss: 0.33 \n",
            "errD0: 0.43 errD1: 0.69 errD2: 0.42 \n",
            "g_loss0: 10.16 g_loss1: 8.98 g_loss2: 8.38 w_loss: 12.13 s_loss: 17.15 kl_loss: 0.32 \n",
            "[46/200][442]\n",
            "                  Loss_D: 2.26 Loss_G: 69.32 Time: 190.47s\n",
            "errD0: 0.43 errD1: 0.47 errD2: 0.86 \n",
            "g_loss0: 11.22 g_loss1: 17.71 g_loss2: 6.32 w_loss: 11.81 s_loss: 18.24 kl_loss: 0.44 \n",
            "errD0: 0.96 errD1: 0.15 errD2: 0.42 \n",
            "g_loss0: 22.46 g_loss1: 15.03 g_loss2: 8.54 w_loss: 11.23 s_loss: 20.01 kl_loss: 0.44 \n",
            "errD0: 0.26 errD1: 0.76 errD2: 0.71 \n",
            "g_loss0: 15.23 g_loss1: 13.66 g_loss2: 13.68 w_loss: 12.52 s_loss: 19.90 kl_loss: 0.30 \n",
            "errD0: 0.12 errD1: 0.17 errD2: 1.02 \n",
            "g_loss0: 13.84 g_loss1: 18.83 g_loss2: 5.80 w_loss: 15.20 s_loss: 19.82 kl_loss: 0.39 \n",
            "errD0: 0.95 errD1: 0.29 errD2: 0.48 \n",
            "g_loss0: 10.38 g_loss1: 4.43 g_loss2: 14.36 w_loss: 13.02 s_loss: 16.06 kl_loss: 0.32 \n",
            "[47/200][442]\n",
            "                  Loss_D: 1.24 Loss_G: 71.73 Time: 229.30s\n",
            "errD0: 0.30 errD1: 0.31 errD2: 0.48 \n",
            "g_loss0: 14.79 g_loss1: 21.86 g_loss2: 7.53 w_loss: 9.92 s_loss: 16.81 kl_loss: 0.46 \n",
            "errD0: 0.25 errD1: 0.16 errD2: 0.43 \n",
            "g_loss0: 10.66 g_loss1: 18.01 g_loss2: 11.05 w_loss: 11.27 s_loss: 19.47 kl_loss: 0.36 \n",
            "errD0: 0.46 errD1: 0.36 errD2: 0.42 \n",
            "g_loss0: 13.28 g_loss1: 9.79 g_loss2: 14.51 w_loss: 11.98 s_loss: 17.88 kl_loss: 0.32 \n",
            "errD0: 1.87 errD1: 0.76 errD2: 0.60 \n",
            "g_loss0: 24.66 g_loss1: 10.13 g_loss2: 3.08 w_loss: 15.48 s_loss: 21.59 kl_loss: 0.54 \n",
            "[48/200][442]\n",
            "                  Loss_D: 0.83 Loss_G: 63.78 Time: 190.37s\n",
            "errD0: 0.18 errD1: 0.58 errD2: 1.60 \n",
            "g_loss0: 11.84 g_loss1: 2.74 g_loss2: 1.22 w_loss: 13.76 s_loss: 19.07 kl_loss: 0.49 \n",
            "errD0: 0.37 errD1: 0.36 errD2: 0.50 \n",
            "g_loss0: 16.20 g_loss1: 17.65 g_loss2: 12.37 w_loss: 9.49 s_loss: 18.10 kl_loss: 0.38 \n",
            "errD0: 1.17 errD1: 0.16 errD2: 0.10 \n",
            "g_loss0: 15.29 g_loss1: 15.49 g_loss2: 23.12 w_loss: 10.23 s_loss: 15.17 kl_loss: 0.37 \n",
            "errD0: 0.24 errD1: 0.49 errD2: 0.26 \n",
            "g_loss0: 5.28 g_loss1: 10.37 g_loss2: 7.95 w_loss: 17.34 s_loss: 20.74 kl_loss: 0.45 \n",
            "errD0: 0.43 errD1: 0.16 errD2: 0.30 \n",
            "g_loss0: 13.01 g_loss1: 13.38 g_loss2: 5.75 w_loss: 14.53 s_loss: 19.35 kl_loss: 0.32 \n",
            "[49/200][442]\n",
            "                  Loss_D: 0.88 Loss_G: 66.33 Time: 228.80s\n",
            "errD0: 0.14 errD1: 0.38 errD2: 0.20 \n",
            "g_loss0: 16.15 g_loss1: 10.86 g_loss2: 11.99 w_loss: 12.11 s_loss: 18.90 kl_loss: 0.45 \n",
            "errD0: 0.07 errD1: 0.13 errD2: 0.05 \n",
            "g_loss0: 10.53 g_loss1: 10.40 g_loss2: 12.22 w_loss: 14.96 s_loss: 16.20 kl_loss: 0.42 \n",
            "errD0: 0.54 errD1: 0.15 errD2: 0.42 \n",
            "g_loss0: 7.86 g_loss1: 14.04 g_loss2: 12.67 w_loss: 12.47 s_loss: 18.76 kl_loss: 0.46 \n",
            "errD0: 0.81 errD1: 0.16 errD2: 0.56 \n",
            "g_loss0: 3.14 g_loss1: 13.77 g_loss2: 12.19 w_loss: 11.60 s_loss: 19.60 kl_loss: 0.33 \n",
            "[50/200][442]\n",
            "                  Loss_D: 1.48 Loss_G: 54.29 Time: 190.16s\n",
            "Save G/Ds models.\n",
            "errD0: 0.25 errD1: 0.15 errD2: 0.56 \n",
            "g_loss0: 7.32 g_loss1: 10.20 g_loss2: 9.57 w_loss: 13.21 s_loss: 18.99 kl_loss: 0.36 \n",
            "errD0: 0.14 errD1: 0.10 errD2: 0.41 \n",
            "g_loss0: 10.96 g_loss1: 12.38 g_loss2: 6.37 w_loss: 13.26 s_loss: 18.37 kl_loss: 0.42 \n",
            "errD0: 0.20 errD1: 0.54 errD2: 0.62 \n",
            "g_loss0: 12.31 g_loss1: 14.23 g_loss2: 10.82 w_loss: 14.57 s_loss: 18.58 kl_loss: 0.40 \n",
            "errD0: 0.26 errD1: 0.25 errD2: 0.31 \n",
            "g_loss0: 11.68 g_loss1: 8.83 g_loss2: 11.47 w_loss: 13.44 s_loss: 19.52 kl_loss: 0.42 \n",
            "[51/200][442]\n",
            "                  Loss_D: 1.44 Loss_G: 74.84 Time: 189.73s\n",
            "errD0: 0.61 errD1: 0.31 errD2: 0.53 \n",
            "g_loss0: 5.83 g_loss1: 10.94 g_loss2: 9.36 w_loss: 11.92 s_loss: 19.89 kl_loss: 0.44 \n",
            "errD0: 0.17 errD1: 0.20 errD2: 0.08 \n",
            "g_loss0: 11.61 g_loss1: 6.89 g_loss2: 8.88 w_loss: 13.45 s_loss: 16.18 kl_loss: 0.42 \n",
            "errD0: 1.42 errD1: 0.30 errD2: 1.08 \n",
            "g_loss0: 6.79 g_loss1: 13.68 g_loss2: 10.04 w_loss: 12.03 s_loss: 19.24 kl_loss: 0.41 \n",
            "errD0: 2.73 errD1: 0.63 errD2: 1.22 \n",
            "g_loss0: 16.87 g_loss1: 13.40 g_loss2: 21.40 w_loss: 12.32 s_loss: 18.75 kl_loss: 0.46 \n",
            "errD0: 1.23 errD1: 1.01 errD2: 0.31 \n",
            "g_loss0: 13.35 g_loss1: 13.25 g_loss2: 9.80 w_loss: 13.43 s_loss: 16.85 kl_loss: 0.37 \n",
            "[52/200][442]\n",
            "                  Loss_D: 0.85 Loss_G: 57.15 Time: 227.55s\n",
            "errD0: 0.19 errD1: 3.24 errD2: 0.31 \n",
            "g_loss0: 13.16 g_loss1: 8.78 g_loss2: 12.25 w_loss: 12.32 s_loss: 17.74 kl_loss: 0.39 \n",
            "errD0: 0.45 errD1: 0.51 errD2: 1.86 \n",
            "g_loss0: 5.71 g_loss1: 8.60 g_loss2: 2.11 w_loss: 12.52 s_loss: 16.27 kl_loss: 0.31 \n",
            "errD0: 0.18 errD1: 0.24 errD2: 0.51 \n",
            "g_loss0: 8.26 g_loss1: 12.43 g_loss2: 18.75 w_loss: 15.06 s_loss: 19.42 kl_loss: 0.33 \n",
            "errD0: 0.35 errD1: 0.34 errD2: 0.40 \n",
            "g_loss0: 4.46 g_loss1: 10.47 g_loss2: 7.86 w_loss: 13.28 s_loss: 17.20 kl_loss: 0.38 \n",
            "[53/200][442]\n",
            "                  Loss_D: 1.69 Loss_G: 68.54 Time: 189.20s\n",
            "errD0: 0.34 errD1: 0.46 errD2: 0.07 \n",
            "g_loss0: 8.68 g_loss1: 9.10 g_loss2: 9.10 w_loss: 12.59 s_loss: 19.67 kl_loss: 0.42 \n",
            "errD0: 0.10 errD1: 0.39 errD2: 0.34 \n",
            "g_loss0: 15.12 g_loss1: 11.99 g_loss2: 8.42 w_loss: 10.15 s_loss: 17.13 kl_loss: 0.31 \n",
            "errD0: 0.32 errD1: 0.36 errD2: 0.24 \n",
            "g_loss0: 8.89 g_loss1: 17.76 g_loss2: 8.01 w_loss: 17.23 s_loss: 20.55 kl_loss: 0.52 \n",
            "errD0: 0.13 errD1: 0.26 errD2: 0.24 \n",
            "g_loss0: 9.91 g_loss1: 3.81 g_loss2: 7.91 w_loss: 14.06 s_loss: 19.04 kl_loss: 0.41 \n",
            "errD0: 0.24 errD1: 0.35 errD2: 1.69 \n",
            "g_loss0: 11.04 g_loss1: 18.98 g_loss2: 9.95 w_loss: 12.90 s_loss: 17.32 kl_loss: 0.39 \n",
            "[54/200][442]\n",
            "                  Loss_D: 2.01 Loss_G: 67.64 Time: 228.42s\n",
            "errD0: 0.05 errD1: 0.83 errD2: 0.27 \n",
            "g_loss0: 11.48 g_loss1: 4.52 g_loss2: 13.65 w_loss: 9.90 s_loss: 19.00 kl_loss: 0.45 \n",
            "errD0: 0.14 errD1: 0.14 errD2: 0.22 \n",
            "g_loss0: 13.49 g_loss1: 18.70 g_loss2: 7.80 w_loss: 15.49 s_loss: 20.35 kl_loss: 0.48 \n",
            "errD0: 0.80 errD1: 1.25 errD2: 0.89 \n",
            "g_loss0: 3.85 g_loss1: 9.28 g_loss2: 5.78 w_loss: 13.04 s_loss: 17.53 kl_loss: 0.34 \n",
            "errD0: 0.42 errD1: 0.63 errD2: 0.23 \n",
            "g_loss0: 10.08 g_loss1: 12.72 g_loss2: 10.81 w_loss: 11.60 s_loss: 18.09 kl_loss: 0.54 \n",
            "[55/200][442]\n",
            "                  Loss_D: 2.16 Loss_G: 73.55 Time: 189.00s\n",
            "errD0: 0.44 errD1: 0.66 errD2: 0.55 \n",
            "g_loss0: 16.38 g_loss1: 14.48 g_loss2: 12.81 w_loss: 13.69 s_loss: 20.19 kl_loss: 0.46 \n",
            "errD0: 0.20 errD1: 0.34 errD2: 0.27 \n",
            "g_loss0: 11.30 g_loss1: 18.66 g_loss2: 10.63 w_loss: 12.59 s_loss: 16.65 kl_loss: 0.49 \n",
            "errD0: 0.95 errD1: 1.47 errD2: 1.33 \n",
            "g_loss0: 8.51 g_loss1: 23.13 g_loss2: 14.62 w_loss: 12.18 s_loss: 18.24 kl_loss: 0.43 \n",
            "errD0: 0.20 errD1: 0.16 errD2: 0.83 \n",
            "g_loss0: 5.22 g_loss1: 14.32 g_loss2: 1.29 w_loss: 12.13 s_loss: 18.95 kl_loss: 0.48 \n",
            "[56/200][442]\n",
            "                  Loss_D: 1.89 Loss_G: 65.02 Time: 228.22s\n",
            "errD0: 0.28 errD1: 0.61 errD2: 0.30 \n",
            "g_loss0: 12.65 g_loss1: 10.18 g_loss2: 14.45 w_loss: 11.32 s_loss: 17.79 kl_loss: 0.50 \n",
            "errD0: 0.21 errD1: 0.22 errD2: 0.26 \n",
            "g_loss0: 9.39 g_loss1: 9.46 g_loss2: 7.86 w_loss: 16.71 s_loss: 18.67 kl_loss: 0.45 \n",
            "errD0: 0.35 errD1: 0.09 errD2: 0.17 \n",
            "g_loss0: 15.47 g_loss1: 10.36 g_loss2: 8.05 w_loss: 14.97 s_loss: 18.61 kl_loss: 0.40 \n",
            "errD0: 0.28 errD1: 0.37 errD2: 0.93 \n",
            "g_loss0: 8.89 g_loss1: 8.36 g_loss2: 8.02 w_loss: 14.16 s_loss: 19.75 kl_loss: 0.40 \n",
            "errD0: 0.16 errD1: 0.09 errD2: 0.15 \n",
            "g_loss0: 11.53 g_loss1: 13.57 g_loss2: 14.92 w_loss: 9.75 s_loss: 15.78 kl_loss: 0.40 \n",
            "[57/200][442]\n",
            "                  Loss_D: 2.17 Loss_G: 56.34 Time: 189.75s\n",
            "errD0: 0.93 errD1: 0.39 errD2: 0.58 \n",
            "g_loss0: 9.90 g_loss1: 8.56 g_loss2: 3.31 w_loss: 10.40 s_loss: 19.38 kl_loss: 0.44 \n",
            "errD0: 0.35 errD1: 0.15 errD2: 0.12 \n",
            "g_loss0: 14.88 g_loss1: 14.56 g_loss2: 9.12 w_loss: 12.73 s_loss: 20.68 kl_loss: 0.51 \n",
            "errD0: 0.32 errD1: 0.34 errD2: 0.17 \n",
            "g_loss0: 11.94 g_loss1: 13.85 g_loss2: 15.67 w_loss: 18.52 s_loss: 19.90 kl_loss: 0.46 \n",
            "errD0: 1.01 errD1: 1.50 errD2: 0.35 \n",
            "g_loss0: 1.86 g_loss1: 15.50 g_loss2: 12.74 w_loss: 14.58 s_loss: 18.42 kl_loss: 0.41 \n",
            "[58/200][442]\n",
            "                  Loss_D: 0.93 Loss_G: 49.09 Time: 230.11s\n",
            "errD0: 0.58 errD1: 0.16 errD2: 0.36 \n",
            "g_loss0: 18.77 g_loss1: 18.11 g_loss2: 13.38 w_loss: 10.87 s_loss: 21.04 kl_loss: 0.48 \n",
            "errD0: 0.39 errD1: 0.24 errD2: 0.65 \n",
            "g_loss0: 9.86 g_loss1: 8.72 g_loss2: 10.00 w_loss: 13.45 s_loss: 19.60 kl_loss: 0.43 \n",
            "errD0: 0.27 errD1: 0.28 errD2: 0.48 \n",
            "g_loss0: 8.27 g_loss1: 11.83 g_loss2: 4.93 w_loss: 15.70 s_loss: 20.07 kl_loss: 0.45 \n",
            "errD0: 0.27 errD1: 0.39 errD2: 0.37 \n",
            "g_loss0: 6.00 g_loss1: 7.56 g_loss2: 7.44 w_loss: 13.08 s_loss: 21.87 kl_loss: 0.46 \n",
            "errD0: 0.16 errD1: 1.50 errD2: 0.45 \n",
            "g_loss0: 14.24 g_loss1: 10.31 g_loss2: 6.84 w_loss: 11.54 s_loss: 17.28 kl_loss: 0.46 \n",
            "[59/200][442]\n",
            "                  Loss_D: 0.62 Loss_G: 63.26 Time: 190.14s\n",
            "errD0: 0.05 errD1: 0.15 errD2: 0.42 \n",
            "g_loss0: 11.00 g_loss1: 9.11 g_loss2: 9.29 w_loss: 14.31 s_loss: 18.64 kl_loss: 0.50 \n",
            "errD0: 0.49 errD1: 0.64 errD2: 1.23 \n",
            "g_loss0: 10.76 g_loss1: 12.07 g_loss2: 5.40 w_loss: 9.89 s_loss: 15.96 kl_loss: 0.36 \n",
            "errD0: 0.09 errD1: 0.21 errD2: 0.14 \n",
            "g_loss0: 11.22 g_loss1: 11.46 g_loss2: 11.10 w_loss: 14.51 s_loss: 18.93 kl_loss: 0.40 \n",
            "errD0: 0.22 errD1: 0.63 errD2: 0.97 \n",
            "g_loss0: 16.17 g_loss1: 11.24 g_loss2: 11.75 w_loss: 12.16 s_loss: 16.17 kl_loss: 0.44 \n",
            "[60/200][442]\n",
            "                  Loss_D: 1.38 Loss_G: 80.49 Time: 189.76s\n",
            "errD0: 1.88 errD1: 0.65 errD2: 0.81 \n",
            "g_loss0: 9.52 g_loss1: 11.65 g_loss2: 7.50 w_loss: 11.99 s_loss: 17.56 kl_loss: 0.43 \n",
            "errD0: 0.11 errD1: 0.09 errD2: 0.49 \n",
            "g_loss0: 10.84 g_loss1: 14.23 g_loss2: 14.66 w_loss: 16.23 s_loss: 19.45 kl_loss: 0.44 \n",
            "errD0: 0.37 errD1: 0.48 errD2: 0.40 \n",
            "g_loss0: 11.05 g_loss1: 15.26 g_loss2: 9.06 w_loss: 11.47 s_loss: 17.33 kl_loss: 0.36 \n",
            "errD0: 0.53 errD1: 0.18 errD2: 0.22 \n",
            "g_loss0: 6.02 g_loss1: 8.71 g_loss2: 11.04 w_loss: 10.96 s_loss: 18.25 kl_loss: 0.36 \n",
            "errD0: 0.92 errD1: 0.18 errD2: 0.52 \n",
            "g_loss0: 2.46 g_loss1: 8.63 g_loss2: 6.16 w_loss: 12.96 s_loss: 19.12 kl_loss: 0.46 \n",
            "[61/200][442]\n",
            "                  Loss_D: 0.99 Loss_G: 64.97 Time: 231.79s\n",
            "errD0: 0.29 errD1: 0.49 errD2: 0.08 \n",
            "g_loss0: 9.56 g_loss1: 10.91 g_loss2: 13.90 w_loss: 9.74 s_loss: 19.06 kl_loss: 0.45 \n",
            "errD0: 0.91 errD1: 0.18 errD2: 0.20 \n",
            "g_loss0: 2.82 g_loss1: 14.58 g_loss2: 6.56 w_loss: 11.01 s_loss: 18.82 kl_loss: 0.45 \n",
            "errD0: 0.25 errD1: 0.16 errD2: 0.13 \n",
            "g_loss0: 14.31 g_loss1: 7.63 g_loss2: 12.24 w_loss: 12.11 s_loss: 17.65 kl_loss: 0.35 \n",
            "errD0: 0.23 errD1: 0.30 errD2: 0.14 \n",
            "g_loss0: 8.21 g_loss1: 9.19 g_loss2: 7.50 w_loss: 12.74 s_loss: 16.98 kl_loss: 0.51 \n",
            "[62/200][442]\n",
            "                  Loss_D: 0.51 Loss_G: 67.87 Time: 189.74s\n",
            "errD0: 0.54 errD1: 0.59 errD2: 0.25 \n",
            "g_loss0: 10.83 g_loss1: 8.90 g_loss2: 12.71 w_loss: 13.50 s_loss: 18.35 kl_loss: 0.40 \n",
            "errD0: 0.34 errD1: 0.37 errD2: 0.39 \n",
            "g_loss0: 11.47 g_loss1: 18.90 g_loss2: 10.89 w_loss: 16.15 s_loss: 21.35 kl_loss: 0.48 \n",
            "errD0: 0.50 errD1: 0.35 errD2: 0.53 \n",
            "g_loss0: 8.24 g_loss1: 13.55 g_loss2: 8.13 w_loss: 10.68 s_loss: 21.38 kl_loss: 0.50 \n",
            "errD0: 0.11 errD1: 0.17 errD2: 0.17 \n",
            "g_loss0: 11.90 g_loss1: 10.49 g_loss2: 9.74 w_loss: 15.85 s_loss: 18.70 kl_loss: 0.44 \n",
            "[63/200][442]\n",
            "                  Loss_D: 0.93 Loss_G: 71.73 Time: 232.55s\n",
            "errD0: 0.06 errD1: 0.20 errD2: 0.21 \n",
            "g_loss0: 9.30 g_loss1: 13.97 g_loss2: 14.80 w_loss: 13.46 s_loss: 17.41 kl_loss: 0.49 \n",
            "errD0: 0.83 errD1: 0.69 errD2: 1.45 \n",
            "g_loss0: 11.04 g_loss1: 11.65 g_loss2: 1.15 w_loss: 9.33 s_loss: 18.42 kl_loss: 0.38 \n",
            "errD0: 0.32 errD1: 0.15 errD2: 0.15 \n",
            "g_loss0: 10.15 g_loss1: 17.32 g_loss2: 21.41 w_loss: 10.73 s_loss: 16.74 kl_loss: 0.53 \n",
            "errD0: 0.06 errD1: 0.05 errD2: 0.24 \n",
            "g_loss0: 17.63 g_loss1: 18.33 g_loss2: 10.61 w_loss: 14.10 s_loss: 18.67 kl_loss: 0.51 \n",
            "errD0: 0.07 errD1: 0.07 errD2: 0.07 \n",
            "g_loss0: 13.75 g_loss1: 17.48 g_loss2: 8.02 w_loss: 15.24 s_loss: 19.05 kl_loss: 0.40 \n",
            "[64/200][442]\n",
            "                  Loss_D: 1.71 Loss_G: 57.13 Time: 190.71s\n",
            "errD0: 0.77 errD1: 0.72 errD2: 0.11 \n",
            "g_loss0: 6.99 g_loss1: 5.97 g_loss2: 9.06 w_loss: 9.32 s_loss: 16.39 kl_loss: 0.45 \n",
            "errD0: 0.05 errD1: 0.18 errD2: 0.22 \n",
            "g_loss0: 12.93 g_loss1: 11.99 g_loss2: 10.84 w_loss: 10.74 s_loss: 19.19 kl_loss: 0.47 \n",
            "errD0: 0.18 errD1: 0.17 errD2: 0.08 \n",
            "g_loss0: 9.98 g_loss1: 14.85 g_loss2: 9.57 w_loss: 9.86 s_loss: 20.42 kl_loss: 0.48 \n",
            "errD0: 0.20 errD1: 0.54 errD2: 0.29 \n",
            "g_loss0: 11.98 g_loss1: 8.64 g_loss2: 12.77 w_loss: 11.87 s_loss: 18.37 kl_loss: 0.45 \n",
            "[65/200][442]\n",
            "                  Loss_D: 0.93 Loss_G: 73.50 Time: 232.51s\n",
            "errD0: 0.60 errD1: 0.43 errD2: 0.53 \n",
            "g_loss0: 11.08 g_loss1: 13.91 g_loss2: 12.65 w_loss: 13.24 s_loss: 18.49 kl_loss: 0.44 \n",
            "errD0: 0.28 errD1: 0.87 errD2: 0.15 \n",
            "g_loss0: 7.63 g_loss1: 6.75 g_loss2: 7.58 w_loss: 9.48 s_loss: 17.18 kl_loss: 0.52 \n",
            "errD0: 0.17 errD1: 0.32 errD2: 0.52 \n",
            "g_loss0: 9.53 g_loss1: 16.81 g_loss2: 4.57 w_loss: 9.47 s_loss: 17.51 kl_loss: 0.45 \n",
            "errD0: 0.41 errD1: 0.17 errD2: 0.05 \n",
            "g_loss0: 7.23 g_loss1: 9.19 g_loss2: 10.83 w_loss: 11.77 s_loss: 17.59 kl_loss: 0.49 \n",
            "errD0: 0.85 errD1: 0.13 errD2: 0.19 \n",
            "g_loss0: 15.83 g_loss1: 8.60 g_loss2: 13.98 w_loss: 12.04 s_loss: 19.35 kl_loss: 0.51 \n",
            "[66/200][442]\n",
            "                  Loss_D: 3.33 Loss_G: 48.32 Time: 190.21s\n",
            "errD0: 0.44 errD1: 0.53 errD2: 0.32 \n",
            "g_loss0: 7.62 g_loss1: 10.24 g_loss2: 8.02 w_loss: 14.01 s_loss: 19.23 kl_loss: 0.48 \n",
            "errD0: 0.06 errD1: 0.59 errD2: 0.23 \n",
            "g_loss0: 8.41 g_loss1: 22.20 g_loss2: 8.82 w_loss: 13.05 s_loss: 19.38 kl_loss: 0.49 \n",
            "errD0: 0.81 errD1: 1.88 errD2: 0.62 \n",
            "g_loss0: 7.20 g_loss1: 14.64 g_loss2: 10.62 w_loss: 15.84 s_loss: 18.48 kl_loss: 0.59 \n",
            "errD0: 0.54 errD1: 0.05 errD2: 0.77 \n",
            "g_loss0: 9.30 g_loss1: 13.49 g_loss2: 1.39 w_loss: 10.69 s_loss: 14.76 kl_loss: 0.54 \n",
            "[67/200][442]\n",
            "                  Loss_D: 1.37 Loss_G: 81.96 Time: 231.62s\n",
            "errD0: 0.09 errD1: 0.31 errD2: 0.41 \n",
            "g_loss0: 10.03 g_loss1: 18.14 g_loss2: 5.99 w_loss: 13.62 s_loss: 18.50 kl_loss: 0.42 \n",
            "errD0: 0.62 errD1: 0.41 errD2: 0.15 \n",
            "g_loss0: 9.51 g_loss1: 11.05 g_loss2: 14.50 w_loss: 12.80 s_loss: 19.58 kl_loss: 0.50 \n",
            "errD0: 0.30 errD1: 0.14 errD2: 0.19 \n",
            "g_loss0: 12.91 g_loss1: 11.63 g_loss2: 13.40 w_loss: 12.48 s_loss: 19.34 kl_loss: 0.51 \n",
            "errD0: 0.29 errD1: 0.43 errD2: 0.23 \n",
            "g_loss0: 7.97 g_loss1: 13.21 g_loss2: 11.29 w_loss: 11.78 s_loss: 17.46 kl_loss: 0.46 \n",
            "[68/200][442]\n",
            "                  Loss_D: 0.72 Loss_G: 64.22 Time: 190.12s\n",
            "errD0: 0.37 errD1: 0.31 errD2: 0.10 \n",
            "g_loss0: 10.27 g_loss1: 17.61 g_loss2: 9.76 w_loss: 10.70 s_loss: 19.17 kl_loss: 0.45 \n",
            "errD0: 0.39 errD1: 0.46 errD2: 0.40 \n",
            "g_loss0: 8.21 g_loss1: 11.02 g_loss2: 21.68 w_loss: 14.78 s_loss: 20.51 kl_loss: 0.62 \n",
            "errD0: 0.48 errD1: 0.29 errD2: 0.64 \n",
            "g_loss0: 11.60 g_loss1: 13.46 g_loss2: 7.43 w_loss: 12.00 s_loss: 17.88 kl_loss: 0.48 \n",
            "errD0: 0.75 errD1: 0.76 errD2: 0.58 \n",
            "g_loss0: 13.41 g_loss1: 11.65 g_loss2: 12.05 w_loss: 15.45 s_loss: 21.78 kl_loss: 0.57 \n",
            "errD0: 0.62 errD1: 0.52 errD2: 0.39 \n",
            "g_loss0: 11.54 g_loss1: 16.13 g_loss2: 16.74 w_loss: 12.04 s_loss: 19.08 kl_loss: 0.43 \n",
            "[69/200][442]\n",
            "                  Loss_D: 1.56 Loss_G: 69.49 Time: 190.06s\n",
            "errD0: 0.71 errD1: 0.76 errD2: 1.38 \n",
            "g_loss0: 9.61 g_loss1: 18.11 g_loss2: 3.52 w_loss: 13.51 s_loss: 18.37 kl_loss: 0.48 \n",
            "errD0: 1.32 errD1: 1.11 errD2: 1.07 \n",
            "g_loss0: 3.70 g_loss1: 18.61 g_loss2: 10.20 w_loss: 12.92 s_loss: 16.78 kl_loss: 0.44 \n",
            "errD0: 0.36 errD1: 0.49 errD2: 2.27 \n",
            "g_loss0: 12.78 g_loss1: 11.43 g_loss2: 5.58 w_loss: 12.61 s_loss: 18.04 kl_loss: 0.50 \n",
            "errD0: 0.79 errD1: 0.41 errD2: 0.46 \n",
            "g_loss0: 9.89 g_loss1: 11.69 g_loss2: 3.84 w_loss: 13.33 s_loss: 16.60 kl_loss: 0.42 \n",
            "[70/200][442]\n",
            "                  Loss_D: 0.74 Loss_G: 74.22 Time: 230.67s\n",
            "errD0: 0.28 errD1: 0.27 errD2: 0.16 \n",
            "g_loss0: 13.34 g_loss1: 11.89 g_loss2: 7.43 w_loss: 14.70 s_loss: 18.91 kl_loss: 0.50 \n",
            "errD0: 0.07 errD1: 0.06 errD2: 0.07 \n",
            "g_loss0: 9.70 g_loss1: 10.52 g_loss2: 6.85 w_loss: 13.22 s_loss: 19.52 kl_loss: 0.56 \n",
            "errD0: 0.14 errD1: 0.02 errD2: 1.40 \n",
            "g_loss0: 11.33 g_loss1: 13.17 g_loss2: 1.43 w_loss: 11.71 s_loss: 17.47 kl_loss: 0.50 \n",
            "errD0: 0.18 errD1: 0.10 errD2: 0.43 \n",
            "g_loss0: 9.08 g_loss1: 10.33 g_loss2: 12.09 w_loss: 15.44 s_loss: 17.74 kl_loss: 0.47 \n",
            "errD0: 0.48 errD1: 0.82 errD2: 0.67 \n",
            "g_loss0: 13.93 g_loss1: 24.60 g_loss2: 18.92 w_loss: 11.98 s_loss: 20.26 kl_loss: 0.59 \n",
            "[71/200][442]\n",
            "                  Loss_D: 0.67 Loss_G: 67.85 Time: 189.91s\n",
            "errD0: 0.24 errD1: 0.12 errD2: 0.09 \n",
            "g_loss0: 11.38 g_loss1: 10.73 g_loss2: 5.80 w_loss: 11.70 s_loss: 17.36 kl_loss: 0.47 \n",
            "errD0: 0.33 errD1: 0.18 errD2: 0.27 \n",
            "g_loss0: 9.78 g_loss1: 12.99 g_loss2: 8.62 w_loss: 14.22 s_loss: 20.45 kl_loss: 0.44 \n",
            "errD0: 1.21 errD1: 1.05 errD2: 0.52 \n",
            "g_loss0: 10.47 g_loss1: 14.78 g_loss2: 8.04 w_loss: 11.56 s_loss: 17.00 kl_loss: 0.49 \n",
            "errD0: 1.54 errD1: 0.20 errD2: 1.69 \n",
            "g_loss0: 17.25 g_loss1: 16.82 g_loss2: 13.95 w_loss: 13.24 s_loss: 21.64 kl_loss: 0.45 \n",
            "[72/200][442]\n",
            "                  Loss_D: 0.47 Loss_G: 81.70 Time: 229.09s\n",
            "errD0: 0.14 errD1: 0.13 errD2: 0.26 \n",
            "g_loss0: 11.08 g_loss1: 11.41 g_loss2: 6.77 w_loss: 15.30 s_loss: 18.22 kl_loss: 0.44 \n",
            "errD0: 0.68 errD1: 0.73 errD2: 0.46 \n",
            "g_loss0: 7.36 g_loss1: 4.86 g_loss2: 6.79 w_loss: 10.34 s_loss: 17.18 kl_loss: 0.47 \n",
            "errD0: 0.19 errD1: 0.86 errD2: 0.12 \n",
            "g_loss0: 12.09 g_loss1: 16.19 g_loss2: 11.45 w_loss: 14.63 s_loss: 20.58 kl_loss: 0.48 \n",
            "errD0: 0.13 errD1: 0.43 errD2: 0.43 \n",
            "g_loss0: 9.13 g_loss1: 10.30 g_loss2: 21.35 w_loss: 12.47 s_loss: 18.99 kl_loss: 0.42 \n",
            "errD0: 0.09 errD1: 0.14 errD2: 0.20 \n",
            "g_loss0: 12.36 g_loss1: 3.96 g_loss2: 7.69 w_loss: 13.69 s_loss: 16.71 kl_loss: 0.47 \n",
            "[73/200][442]\n",
            "                  Loss_D: 2.08 Loss_G: 58.51 Time: 190.01s\n",
            "errD0: 0.26 errD1: 0.27 errD2: 0.24 \n",
            "g_loss0: 22.07 g_loss1: 11.64 g_loss2: 8.39 w_loss: 12.56 s_loss: 18.23 kl_loss: 0.59 \n",
            "errD0: 0.16 errD1: 0.55 errD2: 2.19 \n",
            "g_loss0: 7.98 g_loss1: 13.75 g_loss2: 10.03 w_loss: 15.32 s_loss: 19.88 kl_loss: 0.52 \n",
            "errD0: 0.21 errD1: 0.32 errD2: 0.23 \n",
            "g_loss0: 9.05 g_loss1: 12.22 g_loss2: 9.60 w_loss: 13.59 s_loss: 18.57 kl_loss: 0.54 \n",
            "errD0: 0.42 errD1: 0.82 errD2: 0.77 \n",
            "g_loss0: 13.38 g_loss1: 10.79 g_loss2: 10.52 w_loss: 13.95 s_loss: 18.80 kl_loss: 0.45 \n",
            "[74/200][442]\n",
            "                  Loss_D: 0.92 Loss_G: 75.62 Time: 231.25s\n",
            "errD0: 0.19 errD1: 0.09 errD2: 0.40 \n",
            "g_loss0: 9.08 g_loss1: 9.61 g_loss2: 15.85 w_loss: 11.08 s_loss: 18.27 kl_loss: 0.59 \n",
            "errD0: 0.31 errD1: 0.19 errD2: 0.18 \n",
            "g_loss0: 16.04 g_loss1: 13.88 g_loss2: 22.12 w_loss: 12.97 s_loss: 17.04 kl_loss: 0.51 \n",
            "errD0: 0.11 errD1: 0.37 errD2: 0.15 \n",
            "g_loss0: 9.61 g_loss1: 13.63 g_loss2: 9.86 w_loss: 10.46 s_loss: 16.45 kl_loss: 0.50 \n",
            "errD0: 0.27 errD1: 0.38 errD2: 0.07 \n",
            "g_loss0: 11.36 g_loss1: 10.11 g_loss2: 18.88 w_loss: 11.64 s_loss: 19.68 kl_loss: 0.56 \n",
            "[75/200][442]\n",
            "                  Loss_D: 0.66 Loss_G: 64.85 Time: 189.36s\n",
            "errD0: 0.22 errD1: 0.20 errD2: 0.56 \n",
            "g_loss0: 16.80 g_loss1: 8.88 g_loss2: 16.18 w_loss: 11.81 s_loss: 18.11 kl_loss: 0.55 \n",
            "errD0: 0.13 errD1: 0.15 errD2: 0.21 \n",
            "g_loss0: 11.97 g_loss1: 11.58 g_loss2: 15.90 w_loss: 13.19 s_loss: 18.29 kl_loss: 0.45 \n",
            "errD0: 0.67 errD1: 0.12 errD2: 0.11 \n",
            "g_loss0: 9.28 g_loss1: 8.99 g_loss2: 11.19 w_loss: 14.24 s_loss: 20.48 kl_loss: 0.60 \n",
            "errD0: 1.77 errD1: 0.32 errD2: 0.82 \n",
            "g_loss0: 18.64 g_loss1: 6.90 g_loss2: 24.43 w_loss: 14.38 s_loss: 17.99 kl_loss: 0.53 \n",
            "errD0: 0.52 errD1: 0.62 errD2: 0.45 \n",
            "g_loss0: 9.47 g_loss1: 12.76 g_loss2: 10.26 w_loss: 11.97 s_loss: 17.33 kl_loss: 0.48 \n",
            "[76/200][442]\n",
            "                  Loss_D: 1.36 Loss_G: 79.53 Time: 227.15s\n",
            "errD0: 0.23 errD1: 0.99 errD2: 0.33 \n",
            "g_loss0: 11.06 g_loss1: 8.39 g_loss2: 6.26 w_loss: 12.68 s_loss: 17.29 kl_loss: 0.59 \n",
            "errD0: 0.63 errD1: 0.74 errD2: 0.22 \n",
            "g_loss0: 11.99 g_loss1: 15.52 g_loss2: 5.65 w_loss: 12.37 s_loss: 15.60 kl_loss: 0.49 \n",
            "errD0: 2.27 errD1: 0.12 errD2: 0.13 \n",
            "g_loss0: 1.28 g_loss1: 10.30 g_loss2: 4.61 w_loss: 12.47 s_loss: 18.84 kl_loss: 0.52 \n",
            "errD0: 0.25 errD1: 0.15 errD2: 0.06 \n",
            "g_loss0: 6.90 g_loss1: 11.26 g_loss2: 12.74 w_loss: 14.05 s_loss: 20.81 kl_loss: 0.59 \n",
            "[77/200][442]\n",
            "                  Loss_D: 0.43 Loss_G: 76.46 Time: 190.38s\n",
            "errD0: 0.11 errD1: 0.42 errD2: 0.33 \n",
            "g_loss0: 8.95 g_loss1: 8.23 g_loss2: 18.89 w_loss: 16.12 s_loss: 19.04 kl_loss: 0.60 \n",
            "errD0: 0.18 errD1: 0.18 errD2: 1.06 \n",
            "g_loss0: 18.04 g_loss1: 22.81 g_loss2: 7.88 w_loss: 15.58 s_loss: 20.19 kl_loss: 0.61 \n",
            "errD0: 0.14 errD1: 0.46 errD2: 0.59 \n",
            "g_loss0: 6.35 g_loss1: 22.50 g_loss2: 10.04 w_loss: 14.04 s_loss: 18.54 kl_loss: 0.51 \n",
            "errD0: 0.28 errD1: 1.26 errD2: 0.31 \n",
            "g_loss0: 9.45 g_loss1: 14.36 g_loss2: 8.21 w_loss: 13.33 s_loss: 20.04 kl_loss: 0.54 \n",
            "errD0: 0.25 errD1: 0.47 errD2: 0.22 \n",
            "g_loss0: 9.33 g_loss1: 17.83 g_loss2: 11.24 w_loss: 9.62 s_loss: 17.75 kl_loss: 0.52 \n",
            "[78/200][442]\n",
            "                  Loss_D: 3.16 Loss_G: 54.81 Time: 190.42s\n",
            "errD0: 0.28 errD1: 0.13 errD2: 1.07 \n",
            "g_loss0: 8.49 g_loss1: 9.10 g_loss2: 15.92 w_loss: 12.69 s_loss: 17.78 kl_loss: 0.54 \n",
            "errD0: 0.03 errD1: 0.01 errD2: 0.05 \n",
            "g_loss0: 14.59 g_loss1: 12.04 g_loss2: 15.21 w_loss: 10.80 s_loss: 15.72 kl_loss: 0.50 \n",
            "errD0: 0.59 errD1: 1.01 errD2: 0.29 \n",
            "g_loss0: 5.23 g_loss1: 14.45 g_loss2: 12.41 w_loss: 13.96 s_loss: 18.73 kl_loss: 0.66 \n",
            "errD0: 0.11 errD1: 0.10 errD2: 0.04 \n",
            "g_loss0: 13.27 g_loss1: 12.14 g_loss2: 11.65 w_loss: 12.09 s_loss: 18.75 kl_loss: 0.59 \n",
            "[79/200][442]\n",
            "                  Loss_D: 0.74 Loss_G: 70.11 Time: 231.45s\n",
            "errD0: 0.42 errD1: 0.18 errD2: 0.44 \n",
            "g_loss0: 7.01 g_loss1: 11.37 g_loss2: 6.79 w_loss: 10.46 s_loss: 17.83 kl_loss: 0.38 \n",
            "errD0: 1.09 errD1: 0.49 errD2: 0.40 \n",
            "g_loss0: 8.68 g_loss1: 23.74 g_loss2: 19.99 w_loss: 12.14 s_loss: 17.64 kl_loss: 0.43 \n",
            "errD0: 0.46 errD1: 0.53 errD2: 0.20 \n",
            "g_loss0: 8.95 g_loss1: 5.81 g_loss2: 5.95 w_loss: 12.68 s_loss: 17.93 kl_loss: 0.54 \n",
            "errD0: 1.07 errD1: 0.31 errD2: 0.43 \n",
            "g_loss0: 15.37 g_loss1: 8.99 g_loss2: 16.75 w_loss: 14.61 s_loss: 18.78 kl_loss: 0.48 \n",
            "errD0: 0.35 errD1: 0.33 errD2: 0.31 \n",
            "g_loss0: 7.64 g_loss1: 17.87 g_loss2: 15.40 w_loss: 15.09 s_loss: 20.49 kl_loss: 0.70 \n",
            "[80/200][442]\n",
            "                  Loss_D: 0.40 Loss_G: 73.60 Time: 190.69s\n",
            "errD0: 0.14 errD1: 0.51 errD2: 0.07 \n",
            "g_loss0: 8.62 g_loss1: 8.19 g_loss2: 8.03 w_loss: 14.32 s_loss: 19.20 kl_loss: 0.62 \n",
            "errD0: 0.70 errD1: 0.75 errD2: 0.41 \n",
            "g_loss0: 4.86 g_loss1: 18.72 g_loss2: 10.95 w_loss: 11.51 s_loss: 15.78 kl_loss: 0.56 \n",
            "errD0: 0.18 errD1: 0.37 errD2: 0.19 \n",
            "g_loss0: 10.03 g_loss1: 12.23 g_loss2: 6.78 w_loss: 11.05 s_loss: 18.16 kl_loss: 0.55 \n",
            "errD0: 1.36 errD1: 0.03 errD2: 0.08 \n",
            "g_loss0: 7.89 g_loss1: 12.58 g_loss2: 5.40 w_loss: 13.56 s_loss: 21.64 kl_loss: 0.72 \n",
            "[81/200][442]\n",
            "                  Loss_D: 3.50 Loss_G: 91.18 Time: 232.52s\n",
            "errD0: 0.69 errD1: 0.52 errD2: 0.38 \n",
            "g_loss0: 13.62 g_loss1: 10.21 g_loss2: 11.87 w_loss: 13.90 s_loss: 17.14 kl_loss: 0.58 \n",
            "errD0: 0.40 errD1: 0.33 errD2: 0.86 \n",
            "g_loss0: 12.25 g_loss1: 13.81 g_loss2: 3.30 w_loss: 14.95 s_loss: 18.12 kl_loss: 0.59 \n",
            "errD0: 0.46 errD1: 0.35 errD2: 0.10 \n",
            "g_loss0: 7.48 g_loss1: 11.70 g_loss2: 11.11 w_loss: 12.97 s_loss: 16.72 kl_loss: 0.53 \n",
            "errD0: 0.29 errD1: 1.68 errD2: 0.20 \n",
            "g_loss0: 11.63 g_loss1: 29.10 g_loss2: 7.54 w_loss: 14.36 s_loss: 19.96 kl_loss: 0.53 \n",
            "[82/200][442]\n",
            "                  Loss_D: 0.54 Loss_G: 58.62 Time: 191.59s\n",
            "errD0: 0.25 errD1: 0.12 errD2: 0.08 \n",
            "g_loss0: 8.39 g_loss1: 15.53 g_loss2: 10.30 w_loss: 15.34 s_loss: 17.89 kl_loss: 0.57 \n",
            "errD0: 0.20 errD1: 0.49 errD2: 0.21 \n",
            "g_loss0: 13.95 g_loss1: 9.48 g_loss2: 13.90 w_loss: 12.98 s_loss: 18.97 kl_loss: 0.73 \n",
            "errD0: 0.88 errD1: 0.13 errD2: 0.28 \n",
            "g_loss0: 12.81 g_loss1: 9.90 g_loss2: 10.45 w_loss: 11.22 s_loss: 19.00 kl_loss: 0.63 \n",
            "errD0: 0.44 errD1: 0.11 errD2: 0.40 \n",
            "g_loss0: 7.11 g_loss1: 9.50 g_loss2: 8.51 w_loss: 15.70 s_loss: 19.88 kl_loss: 0.56 \n",
            "errD0: 0.41 errD1: 0.26 errD2: 0.91 \n",
            "g_loss0: 10.92 g_loss1: 20.05 g_loss2: 8.83 w_loss: 13.64 s_loss: 19.37 kl_loss: 0.62 \n",
            "[83/200][442]\n",
            "                  Loss_D: 0.47 Loss_G: 63.84 Time: 226.61s\n",
            "errD0: 0.34 errD1: 0.40 errD2: 0.29 \n",
            "g_loss0: 8.14 g_loss1: 8.07 g_loss2: 11.80 w_loss: 10.16 s_loss: 19.27 kl_loss: 0.59 \n",
            "errD0: 0.25 errD1: 0.59 errD2: 1.22 \n",
            "g_loss0: 13.32 g_loss1: 13.56 g_loss2: 9.25 w_loss: 8.45 s_loss: 17.48 kl_loss: 0.56 \n",
            "errD0: 0.22 errD1: 0.16 errD2: 0.63 \n",
            "g_loss0: 14.05 g_loss1: 19.03 g_loss2: 10.67 w_loss: 11.57 s_loss: 16.44 kl_loss: 0.61 \n",
            "errD0: 0.30 errD1: 0.11 errD2: 0.13 \n",
            "g_loss0: 8.85 g_loss1: 15.74 g_loss2: 11.30 w_loss: 8.18 s_loss: 16.51 kl_loss: 0.50 \n",
            "[84/200][442]\n",
            "                  Loss_D: 1.82 Loss_G: 83.72 Time: 190.21s\n",
            "errD0: 0.26 errD1: 0.11 errD2: 0.49 \n",
            "g_loss0: 13.12 g_loss1: 14.27 g_loss2: 13.33 w_loss: 16.52 s_loss: 23.30 kl_loss: 0.60 \n",
            "errD0: 0.74 errD1: 1.00 errD2: 1.37 \n",
            "g_loss0: 5.54 g_loss1: 3.33 g_loss2: 21.05 w_loss: 12.51 s_loss: 19.13 kl_loss: 0.60 \n",
            "errD0: 0.19 errD1: 0.35 errD2: 0.07 \n",
            "g_loss0: 21.94 g_loss1: 17.89 g_loss2: 10.23 w_loss: 11.99 s_loss: 16.84 kl_loss: 0.50 \n",
            "errD0: 0.45 errD1: 0.78 errD2: 0.06 \n",
            "g_loss0: 10.13 g_loss1: 8.47 g_loss2: 7.46 w_loss: 9.77 s_loss: 17.67 kl_loss: 0.63 \n",
            "errD0: 0.15 errD1: 0.08 errD2: 0.34 \n",
            "g_loss0: 8.44 g_loss1: 10.35 g_loss2: 10.45 w_loss: 12.67 s_loss: 16.47 kl_loss: 0.54 \n",
            "[85/200][442]\n",
            "                  Loss_D: 0.39 Loss_G: 90.41 Time: 230.56s\n",
            "errD0: 0.53 errD1: 0.22 errD2: 0.29 \n",
            "g_loss0: 10.90 g_loss1: 8.12 g_loss2: 14.09 w_loss: 13.57 s_loss: 17.45 kl_loss: 0.53 \n",
            "errD0: 1.24 errD1: 0.42 errD2: 0.67 \n",
            "g_loss0: 6.16 g_loss1: 19.93 g_loss2: 26.09 w_loss: 9.42 s_loss: 19.45 kl_loss: 0.49 \n",
            "errD0: 0.26 errD1: 0.36 errD2: 0.43 \n",
            "g_loss0: 12.25 g_loss1: 14.81 g_loss2: 8.42 w_loss: 12.15 s_loss: 17.42 kl_loss: 0.56 \n",
            "errD0: 0.14 errD1: 0.07 errD2: 0.94 \n",
            "g_loss0: 14.69 g_loss1: 11.85 g_loss2: 17.95 w_loss: 15.40 s_loss: 19.94 kl_loss: 0.59 \n",
            "[86/200][442]\n",
            "                  Loss_D: 1.36 Loss_G: 60.40 Time: 190.20s\n",
            "errD0: 0.42 errD1: 0.89 errD2: 0.13 \n",
            "g_loss0: 10.79 g_loss1: 21.35 g_loss2: 11.00 w_loss: 13.38 s_loss: 17.15 kl_loss: 0.52 \n",
            "errD0: 0.66 errD1: 0.11 errD2: 0.11 \n",
            "g_loss0: 4.56 g_loss1: 11.60 g_loss2: 12.64 w_loss: 9.79 s_loss: 17.05 kl_loss: 0.72 \n",
            "errD0: 0.27 errD1: 0.28 errD2: 0.33 \n",
            "g_loss0: 14.62 g_loss1: 12.69 g_loss2: 9.29 w_loss: 8.38 s_loss: 14.22 kl_loss: 0.54 \n",
            "errD0: 0.70 errD1: 0.69 errD2: 0.27 \n",
            "g_loss0: 5.48 g_loss1: 6.44 g_loss2: 11.26 w_loss: 9.35 s_loss: 18.14 kl_loss: 0.61 \n",
            "[87/200][442]\n",
            "                  Loss_D: 0.58 Loss_G: 74.97 Time: 189.87s\n",
            "errD0: 0.88 errD1: 0.78 errD2: 0.53 \n",
            "g_loss0: 4.28 g_loss1: 9.72 g_loss2: 4.52 w_loss: 15.87 s_loss: 18.86 kl_loss: 0.63 \n",
            "errD0: 0.25 errD1: 2.19 errD2: 1.44 \n",
            "g_loss0: 4.78 g_loss1: 18.85 g_loss2: 19.45 w_loss: 12.92 s_loss: 17.98 kl_loss: 0.52 \n",
            "errD0: 1.46 errD1: 0.41 errD2: 0.35 \n",
            "g_loss0: 0.07 g_loss1: 11.31 g_loss2: 12.97 w_loss: 11.25 s_loss: 16.87 kl_loss: 0.56 \n",
            "errD0: 0.84 errD1: 0.72 errD2: 0.48 \n",
            "g_loss0: 8.59 g_loss1: 13.34 g_loss2: 11.94 w_loss: 15.12 s_loss: 17.05 kl_loss: 0.54 \n",
            "errD0: 0.23 errD1: 0.20 errD2: 0.12 \n",
            "g_loss0: 5.55 g_loss1: 12.14 g_loss2: 14.74 w_loss: 13.05 s_loss: 18.28 kl_loss: 0.64 \n",
            "[88/200][442]\n",
            "                  Loss_D: 0.80 Loss_G: 67.01 Time: 230.27s\n",
            "errD0: 0.07 errD1: 0.13 errD2: 0.21 \n",
            "g_loss0: 15.07 g_loss1: 14.72 g_loss2: 12.48 w_loss: 10.71 s_loss: 16.51 kl_loss: 0.45 \n",
            "errD0: 0.16 errD1: 0.75 errD2: 2.95 \n",
            "g_loss0: 9.49 g_loss1: 19.14 g_loss2: 5.73 w_loss: 14.87 s_loss: 19.85 kl_loss: 0.60 \n",
            "errD0: 0.30 errD1: 0.33 errD2: 0.16 \n",
            "g_loss0: 16.58 g_loss1: 12.21 g_loss2: 11.04 w_loss: 12.40 s_loss: 19.75 kl_loss: 0.71 \n",
            "errD0: 0.13 errD1: 0.12 errD2: 0.18 \n",
            "g_loss0: 10.89 g_loss1: 10.27 g_loss2: 8.02 w_loss: 14.73 s_loss: 18.29 kl_loss: 0.66 \n",
            "[89/200][442]\n",
            "                  Loss_D: 1.00 Loss_G: 57.46 Time: 190.10s\n",
            "errD0: 0.13 errD1: 0.10 errD2: 0.25 \n",
            "g_loss0: 10.94 g_loss1: 13.43 g_loss2: 17.06 w_loss: 14.71 s_loss: 19.45 kl_loss: 0.70 \n",
            "errD0: 0.82 errD1: 0.96 errD2: 0.98 \n",
            "g_loss0: 9.09 g_loss1: 20.76 g_loss2: 12.31 w_loss: 10.40 s_loss: 16.40 kl_loss: 0.63 \n",
            "errD0: 0.60 errD1: 0.51 errD2: 0.30 \n",
            "g_loss0: 4.90 g_loss1: 7.90 g_loss2: 19.63 w_loss: 12.17 s_loss: 17.16 kl_loss: 0.52 \n",
            "errD0: 0.61 errD1: 0.66 errD2: 0.25 \n",
            "g_loss0: 4.76 g_loss1: 24.91 g_loss2: 12.70 w_loss: 14.33 s_loss: 17.68 kl_loss: 0.53 \n",
            "errD0: 0.39 errD1: 0.95 errD2: 0.05 \n",
            "g_loss0: 12.59 g_loss1: 5.64 g_loss2: 10.61 w_loss: 16.79 s_loss: 18.49 kl_loss: 0.62 \n",
            "[90/200][442]\n",
            "                  Loss_D: 1.03 Loss_G: 68.53 Time: 228.93s\n",
            "errD0: 0.34 errD1: 0.41 errD2: 0.15 \n",
            "g_loss0: 13.44 g_loss1: 15.24 g_loss2: 9.74 w_loss: 9.94 s_loss: 16.65 kl_loss: 0.63 \n",
            "errD0: 0.64 errD1: 0.37 errD2: 1.68 \n",
            "g_loss0: 13.65 g_loss1: 8.56 g_loss2: 1.04 w_loss: 16.17 s_loss: 18.57 kl_loss: 0.62 \n",
            "errD0: 0.38 errD1: 0.14 errD2: 0.16 \n",
            "g_loss0: 3.95 g_loss1: 13.91 g_loss2: 7.25 w_loss: 16.06 s_loss: 18.85 kl_loss: 0.74 \n",
            "errD0: 0.19 errD1: 0.44 errD2: 0.07 \n",
            "g_loss0: 7.81 g_loss1: 12.86 g_loss2: 7.28 w_loss: 11.58 s_loss: 18.65 kl_loss: 0.60 \n",
            "[91/200][442]\n",
            "                  Loss_D: 0.56 Loss_G: 71.88 Time: 189.69s\n",
            "errD0: 0.41 errD1: 0.19 errD2: 0.04 \n",
            "g_loss0: 12.51 g_loss1: 18.75 g_loss2: 10.46 w_loss: 13.97 s_loss: 17.43 kl_loss: 0.62 \n",
            "errD0: 1.01 errD1: 0.10 errD2: 0.29 \n",
            "g_loss0: 21.11 g_loss1: 8.22 g_loss2: 11.52 w_loss: 13.95 s_loss: 17.58 kl_loss: 0.57 \n",
            "errD0: 0.58 errD1: 0.25 errD2: 0.15 \n",
            "g_loss0: 13.53 g_loss1: 16.07 g_loss2: 10.27 w_loss: 12.35 s_loss: 18.94 kl_loss: 0.59 \n",
            "errD0: 0.60 errD1: 0.11 errD2: 0.57 \n",
            "g_loss0: 16.41 g_loss1: 13.72 g_loss2: 19.34 w_loss: 11.07 s_loss: 16.80 kl_loss: 0.46 \n",
            "errD0: 0.29 errD1: 0.27 errD2: 0.37 \n",
            "g_loss0: 7.79 g_loss1: 7.03 g_loss2: 3.26 w_loss: 13.12 s_loss: 18.42 kl_loss: 0.53 \n",
            "[92/200][442]\n",
            "                  Loss_D: 0.36 Loss_G: 61.48 Time: 227.68s\n",
            "errD0: 0.15 errD1: 1.01 errD2: 0.09 \n",
            "g_loss0: 7.82 g_loss1: 14.97 g_loss2: 8.34 w_loss: 11.76 s_loss: 17.70 kl_loss: 0.59 \n",
            "errD0: 0.23 errD1: 0.37 errD2: 0.49 \n",
            "g_loss0: 7.38 g_loss1: 13.06 g_loss2: 21.78 w_loss: 13.46 s_loss: 18.27 kl_loss: 0.61 \n",
            "errD0: 0.21 errD1: 0.25 errD2: 0.38 \n",
            "g_loss0: 7.38 g_loss1: 15.15 g_loss2: 11.03 w_loss: 10.95 s_loss: 17.04 kl_loss: 0.55 \n",
            "errD0: 0.32 errD1: 0.06 errD2: 0.16 \n",
            "g_loss0: 11.58 g_loss1: 12.75 g_loss2: 10.71 w_loss: 13.29 s_loss: 19.61 kl_loss: 0.54 \n",
            "[93/200][442]\n",
            "                  Loss_D: 0.19 Loss_G: 68.49 Time: 189.92s\n",
            "errD0: 0.33 errD1: 0.09 errD2: 0.03 \n",
            "g_loss0: 12.88 g_loss1: 7.90 g_loss2: 17.85 w_loss: 10.95 s_loss: 18.23 kl_loss: 0.62 \n",
            "errD0: 0.28 errD1: 0.41 errD2: 0.09 \n",
            "g_loss0: 10.96 g_loss1: 10.97 g_loss2: 8.20 w_loss: 12.81 s_loss: 16.19 kl_loss: 0.63 \n",
            "errD0: 0.09 errD1: 0.65 errD2: 0.06 \n",
            "g_loss0: 17.69 g_loss1: 10.70 g_loss2: 10.09 w_loss: 14.77 s_loss: 18.84 kl_loss: 0.62 \n",
            "errD0: 0.03 errD1: 0.09 errD2: 0.12 \n",
            "g_loss0: 13.36 g_loss1: 12.02 g_loss2: 19.36 w_loss: 10.55 s_loss: 17.85 kl_loss: 0.60 \n",
            "[94/200][442]\n",
            "                  Loss_D: 3.01 Loss_G: 62.31 Time: 190.05s\n",
            "errD0: 0.86 errD1: 0.13 errD2: 0.11 \n",
            "g_loss0: 19.32 g_loss1: 11.47 g_loss2: 7.57 w_loss: 12.04 s_loss: 22.54 kl_loss: 0.62 \n",
            "errD0: 0.09 errD1: 0.18 errD2: 0.46 \n",
            "g_loss0: 14.28 g_loss1: 10.70 g_loss2: 14.11 w_loss: 15.56 s_loss: 23.80 kl_loss: 0.58 \n",
            "errD0: 1.15 errD1: 1.10 errD2: 0.22 \n",
            "g_loss0: 17.42 g_loss1: 20.44 g_loss2: 8.11 w_loss: 12.61 s_loss: 16.29 kl_loss: 0.55 \n",
            "errD0: 0.28 errD1: 1.33 errD2: 0.14 \n",
            "g_loss0: 10.13 g_loss1: 1.21 g_loss2: 7.77 w_loss: 13.48 s_loss: 20.51 kl_loss: 0.55 \n",
            "errD0: 0.18 errD1: 0.13 errD2: 0.08 \n",
            "g_loss0: 14.07 g_loss1: 20.87 g_loss2: 15.35 w_loss: 14.49 s_loss: 19.72 kl_loss: 0.54 \n",
            "[95/200][442]\n",
            "                  Loss_D: 0.94 Loss_G: 69.27 Time: 229.48s\n",
            "errD0: 0.39 errD1: 0.25 errD2: 0.12 \n",
            "g_loss0: 8.30 g_loss1: 9.66 g_loss2: 6.54 w_loss: 14.55 s_loss: 18.65 kl_loss: 0.47 \n",
            "errD0: 0.27 errD1: 0.03 errD2: 0.07 \n",
            "g_loss0: 16.93 g_loss1: 14.58 g_loss2: 9.20 w_loss: 15.98 s_loss: 18.31 kl_loss: 0.60 \n",
            "errD0: 0.12 errD1: 0.40 errD2: 0.07 \n",
            "g_loss0: 11.91 g_loss1: 15.70 g_loss2: 12.19 w_loss: 14.96 s_loss: 21.46 kl_loss: 0.70 \n",
            "errD0: 0.13 errD1: 0.19 errD2: 0.13 \n",
            "g_loss0: 11.01 g_loss1: 13.75 g_loss2: 9.22 w_loss: 10.72 s_loss: 17.06 kl_loss: 0.61 \n",
            "[96/200][442]\n",
            "                  Loss_D: 0.38 Loss_G: 66.99 Time: 189.75s\n",
            "errD0: 0.15 errD1: 0.07 errD2: 0.04 \n",
            "g_loss0: 10.39 g_loss1: 15.22 g_loss2: 13.79 w_loss: 12.91 s_loss: 18.47 kl_loss: 0.71 \n",
            "errD0: 0.17 errD1: 0.07 errD2: 0.73 \n",
            "g_loss0: 8.92 g_loss1: 14.42 g_loss2: 9.31 w_loss: 12.74 s_loss: 21.54 kl_loss: 0.69 \n",
            "errD0: 0.25 errD1: 0.04 errD2: 0.03 \n",
            "g_loss0: 13.20 g_loss1: 10.20 g_loss2: 14.28 w_loss: 14.42 s_loss: 20.56 kl_loss: 0.61 \n",
            "errD0: 0.73 errD1: 0.54 errD2: 0.16 \n",
            "g_loss0: 14.92 g_loss1: 17.82 g_loss2: 6.46 w_loss: 12.00 s_loss: 18.47 kl_loss: 0.59 \n",
            "errD0: 0.09 errD1: 0.23 errD2: 0.04 \n",
            "g_loss0: 13.73 g_loss1: 17.95 g_loss2: 10.88 w_loss: 13.60 s_loss: 18.65 kl_loss: 0.73 \n",
            "[97/200][442]\n",
            "                  Loss_D: 1.68 Loss_G: 82.36 Time: 226.47s\n",
            "errD0: 0.04 errD1: 0.36 errD2: 0.03 \n",
            "g_loss0: 9.70 g_loss1: 4.32 g_loss2: 11.55 w_loss: 14.26 s_loss: 21.23 kl_loss: 0.54 \n",
            "errD0: 0.61 errD1: 0.54 errD2: 0.08 \n",
            "g_loss0: 13.07 g_loss1: 16.70 g_loss2: 14.28 w_loss: 10.40 s_loss: 17.83 kl_loss: 0.59 \n",
            "errD0: 0.79 errD1: 1.52 errD2: 0.61 \n",
            "g_loss0: 15.55 g_loss1: 12.13 g_loss2: 11.75 w_loss: 8.97 s_loss: 16.92 kl_loss: 0.61 \n",
            "errD0: 1.19 errD1: 0.99 errD2: 0.52 \n",
            "g_loss0: 11.12 g_loss1: 10.12 g_loss2: 10.51 w_loss: 16.28 s_loss: 19.34 kl_loss: 0.61 \n",
            "[98/200][442]\n",
            "                  Loss_D: 0.85 Loss_G: 65.89 Time: 190.61s\n",
            "errD0: 0.22 errD1: 0.52 errD2: 1.07 \n",
            "g_loss0: 7.35 g_loss1: 10.53 g_loss2: 21.34 w_loss: 12.48 s_loss: 17.47 kl_loss: 0.66 \n",
            "errD0: 1.03 errD1: 0.51 errD2: 1.83 \n",
            "g_loss0: 12.16 g_loss1: 13.60 g_loss2: 1.70 w_loss: 14.32 s_loss: 17.95 kl_loss: 0.60 \n",
            "errD0: 0.72 errD1: 0.68 errD2: 0.08 \n",
            "g_loss0: 15.74 g_loss1: 22.14 g_loss2: 17.24 w_loss: 12.46 s_loss: 19.04 kl_loss: 0.65 \n",
            "errD0: 0.19 errD1: 0.38 errD2: 0.02 \n",
            "g_loss0: 9.99 g_loss1: 10.44 g_loss2: 15.82 w_loss: 15.93 s_loss: 20.60 kl_loss: 0.56 \n",
            "errD0: 0.83 errD1: 0.07 errD2: 0.36 \n",
            "g_loss0: 4.07 g_loss1: 11.67 g_loss2: 16.65 w_loss: 15.95 s_loss: 20.44 kl_loss: 0.69 \n",
            "[99/200][442]\n",
            "                  Loss_D: 1.25 Loss_G: 69.46 Time: 229.69s\n",
            "errD0: 0.17 errD1: 0.51 errD2: 0.08 \n",
            "g_loss0: 11.47 g_loss1: 9.39 g_loss2: 10.03 w_loss: 12.14 s_loss: 17.97 kl_loss: 0.71 \n",
            "errD0: 0.11 errD1: 0.23 errD2: 0.09 \n",
            "g_loss0: 9.81 g_loss1: 15.42 g_loss2: 9.67 w_loss: 12.75 s_loss: 19.45 kl_loss: 0.63 \n",
            "errD0: 0.12 errD1: 0.16 errD2: 0.15 \n",
            "g_loss0: 13.33 g_loss1: 11.06 g_loss2: 11.16 w_loss: 10.86 s_loss: 18.44 kl_loss: 0.53 \n",
            "errD0: 1.07 errD1: 2.26 errD2: 0.37 \n",
            "g_loss0: 15.54 g_loss1: 7.55 g_loss2: 21.52 w_loss: 9.96 s_loss: 19.81 kl_loss: 0.59 \n",
            "[100/200][442]\n",
            "                  Loss_D: 0.47 Loss_G: 67.41 Time: 190.65s\n",
            "Save G/Ds models.\n",
            "errD0: 0.52 errD1: 1.37 errD2: 0.68 \n",
            "g_loss0: 19.78 g_loss1: 13.16 g_loss2: 9.38 w_loss: 10.85 s_loss: 19.30 kl_loss: 0.54 \n",
            "errD0: 0.52 errD1: 0.59 errD2: 0.18 \n",
            "g_loss0: 7.80 g_loss1: 21.11 g_loss2: 15.01 w_loss: 14.87 s_loss: 20.33 kl_loss: 0.61 \n",
            "errD0: 0.07 errD1: 0.04 errD2: 0.18 \n",
            "g_loss0: 18.11 g_loss1: 11.16 g_loss2: 11.20 w_loss: 11.61 s_loss: 17.40 kl_loss: 0.63 \n",
            "errD0: 0.33 errD1: 0.27 errD2: 0.31 \n",
            "g_loss0: 11.02 g_loss1: 13.95 g_loss2: 6.91 w_loss: 15.58 s_loss: 18.07 kl_loss: 0.62 \n",
            "[101/200][442]\n",
            "                  Loss_D: 1.83 Loss_G: 59.39 Time: 226.83s\n",
            "errD0: 0.33 errD1: 0.42 errD2: 0.02 \n",
            "g_loss0: 9.87 g_loss1: 17.13 g_loss2: 10.44 w_loss: 10.38 s_loss: 18.03 kl_loss: 0.60 \n",
            "errD0: 0.22 errD1: 0.30 errD2: 0.05 \n",
            "g_loss0: 18.83 g_loss1: 17.63 g_loss2: 7.30 w_loss: 14.41 s_loss: 17.46 kl_loss: 0.69 \n",
            "errD0: 0.55 errD1: 0.31 errD2: 0.25 \n",
            "g_loss0: 10.44 g_loss1: 16.42 g_loss2: 12.98 w_loss: 12.62 s_loss: 18.13 kl_loss: 0.59 \n",
            "errD0: 0.16 errD1: 0.14 errD2: 0.53 \n",
            "g_loss0: 10.86 g_loss1: 7.39 g_loss2: 4.84 w_loss: 11.84 s_loss: 18.27 kl_loss: 0.59 \n",
            "errD0: 0.88 errD1: 0.32 errD2: 0.16 \n",
            "g_loss0: 4.42 g_loss1: 13.23 g_loss2: 10.98 w_loss: 11.74 s_loss: 18.90 kl_loss: 0.66 \n",
            "[102/200][442]\n",
            "                  Loss_D: 0.79 Loss_G: 64.42 Time: 190.13s\n",
            "errD0: 0.10 errD1: 0.01 errD2: 0.15 \n",
            "g_loss0: 10.33 g_loss1: 15.98 g_loss2: 22.77 w_loss: 15.23 s_loss: 17.80 kl_loss: 0.77 \n",
            "errD0: 0.09 errD1: 0.16 errD2: 0.07 \n",
            "g_loss0: 12.35 g_loss1: 10.36 g_loss2: 21.12 w_loss: 12.94 s_loss: 15.98 kl_loss: 0.60 \n",
            "errD0: 0.51 errD1: 0.48 errD2: 0.24 \n",
            "g_loss0: 5.99 g_loss1: 11.52 g_loss2: 14.11 w_loss: 15.82 s_loss: 20.17 kl_loss: 0.62 \n",
            "errD0: 0.41 errD1: 0.25 errD2: 4.15 \n",
            "g_loss0: 13.60 g_loss1: 9.49 g_loss2: 1.73 w_loss: 12.76 s_loss: 19.25 kl_loss: 0.62 \n",
            "[103/200][442]\n",
            "                  Loss_D: 2.29 Loss_G: 67.79 Time: 189.84s\n",
            "errD0: 0.77 errD1: 0.59 errD2: 1.63 \n",
            "g_loss0: 12.19 g_loss1: 19.95 g_loss2: 20.23 w_loss: 9.67 s_loss: 16.86 kl_loss: 0.63 \n",
            "errD0: 0.15 errD1: 0.17 errD2: 0.09 \n",
            "g_loss0: 7.84 g_loss1: 7.31 g_loss2: 8.95 w_loss: 10.12 s_loss: 16.25 kl_loss: 0.55 \n",
            "errD0: 0.31 errD1: 0.24 errD2: 0.46 \n",
            "g_loss0: 8.41 g_loss1: 12.78 g_loss2: 12.47 w_loss: 14.73 s_loss: 21.86 kl_loss: 0.59 \n",
            "errD0: 0.17 errD1: 0.99 errD2: 0.06 \n",
            "g_loss0: 15.90 g_loss1: 16.84 g_loss2: 12.98 w_loss: 13.87 s_loss: 19.54 kl_loss: 0.58 \n",
            "errD0: 0.13 errD1: 0.13 errD2: 0.58 \n",
            "g_loss0: 11.66 g_loss1: 24.15 g_loss2: 10.73 w_loss: 12.23 s_loss: 19.03 kl_loss: 0.73 \n",
            "[104/200][442]\n",
            "                  Loss_D: 0.46 Loss_G: 74.82 Time: 227.39s\n",
            "errD0: 0.11 errD1: 0.25 errD2: 0.04 \n",
            "g_loss0: 11.43 g_loss1: 10.25 g_loss2: 7.15 w_loss: 13.20 s_loss: 17.47 kl_loss: 0.67 \n",
            "errD0: 0.19 errD1: 0.20 errD2: 0.16 \n",
            "g_loss0: 12.34 g_loss1: 21.20 g_loss2: 15.03 w_loss: 13.34 s_loss: 18.72 kl_loss: 0.71 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF5mUv1wd8W0",
        "outputId": "bf55cf0e-e7ff-40ee-ea07-b3dbdb184e5a"
      },
      "source": [
        "#need to remove the decode\n",
        "%run main.py --cfg cfg/eval_bird.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 25},\n",
            " 'TRAIN': {'BATCH_SIZE': 100,\n",
            "           'B_NET_D': False,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': False,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder200.pth',\n",
            "           'NET_G': '../models/netG_epoch_200.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 5.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 1.0},\n",
            "           'SNAPSHOT_INTERVAL': 2000},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 1}\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "Load from: text/180.Wilson_Warbler/Wilson_Warbler_0007_175618\n",
            "Load from: text/180.Wilson_Warbler/Wilson_Warbler_0024_175278\n",
            "Load from: text/180.Wilson_Warbler/Wilson_Warbler_0074_175645\n",
            "Load from: text/180.Wilson_Warbler/Wilson_Warbler_0107_175320\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0001_163813\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0008_164001\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0016_164060\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0035_163587\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0101_164324\n",
            "Load from: text/165.Chestnut_sided_Warbler/Chestnut_Sided_Warbler_0103_163669\n",
            "Load from: text/138.Tree_Swallow/Tree_Swallow_0002_136792\n",
            "Load from: text/138.Tree_Swallow/Tree_Swallow_0008_135352\n",
            "Load from: text/138.Tree_Swallow/Tree_Swallow_0030_134942\n",
            "Load from: text/138.Tree_Swallow/Tree_Swallow_0050_135104\n",
            "Load from: text/138.Tree_Swallow/Tree_Swallow_0117_134925\n",
            "Load from: text/098.Scott_Oriole/Scott_Oriole_0002_795829\n",
            "Load from: text/098.Scott_Oriole/Scott_Oriole_0014_795827\n",
            "Load from: text/098.Scott_Oriole/Scott_Oriole_0018_795840\n",
            "Load from: text/098.Scott_Oriole/Scott_Oriole_0046_92371\n",
            "Load from: text/035.Purple_Finch/Purple_Finch_0013_27506\n",
            "Load from: text/035.Purple_Finch/Purple_Finch_0014_27322\n",
            "Load from: text/035.Purple_Finch/Purple_Finch_0023_27986\n",
            "Load from: text/035.Purple_Finch/Purple_Finch_0025_28174\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load G from:  ../models/netG_epoch_200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AttnGAN/code/trainer.py:466: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  captions = Variable(torch.from_numpy(captions), volatile=True)\n",
            "/content/drive/MyDrive/AttnGAN/code/trainer.py:467: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  cap_lens = Variable(torch.from_numpy(cap_lens), volatile=True)\n",
            "/content/drive/MyDrive/AttnGAN/code/trainer.py:472: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/MyDrive/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/drive/MyDrive/AttnGAN/code/miscc/utils.py:236: RuntimeWarning: invalid value encountered in true_divide\n",
            "  one_map = (one_map - minV) / (maxV - minV)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total time for training: 527.6199808120728\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}